# AI-QA Agent User Stories

## üìã **Epic Overview: AI-Powered Mobile Test Automation Platform**

**Vision**: Enable manual testers to automate repetitive test cases using natural language commands with minimal scripting knowledge.

**Business Value**: Reduce manual testing time by 70%, enable non-technical testers to create automation, and provide self-healing test capabilities.

---

## üéØ **Sprint Planning Overview**

| Sprint | Stories | Focus Area | Key Deliverables |
|--------|---------|------------|-----------------|
| **Sprint 1** | Stories 1-2 | UI Foundation | Basic interface, command input, device management |
| **Sprint 2** | Stories 3-4 | Visual Experience | Emulator display, execution controls, state management |
| **Sprint 3** | Stories 5, 9 | Logging & Inspection | Execution logs, UI element tree, tab navigation |
| **Sprint 4** | Stories 6, 8 | AI Integration Core | LLM API integration, plan generation, UI context |
| **Sprint 5** | Story 7 | AI Self-Healing | Replanning service, failure recovery, adaptive logic |
| **Sprint 6** | Story 10 | AI Enhancement | Few-shot learning, advanced prompting, knowledge base |
| **Sprint 7** | Story 11 | Real Device Control | Appium integration, live execution, screenshot streaming |
| **Sprint 8** | Story 12 | End-to-End Validation | Complete system testing, performance validation |

### MVP Additions to Existing Stories

- **Story 5: Execution Log & Step Timeline (MVP Additions)**
  - Persist `test_runs` and `test_steps` to database; store screenshots and page sources in object storage and reference them from steps.
  - History tab reads recent runs from DB (no mocks), supports pagination and basic filters; allow download of HTML/JSON report per run.

- **Story 6: LLM Integration & Plan Generation (MVP Additions)**
  - Enforce JSON Schema validation on LLM output; auto-regenerate up to N attempts on schema failure.
  - Impose token/context and step-count caps; safely trim UI context; deterministic fallback plan when AI service fails.

- **Story 9: UI Inspector & Element Tree (MVP Additions)**
  - Allow pin/unpin of elements from the tree; maintain preferred selectors list for the current run.
  - Show when pinned selectors are used in plan/replan; provide "Reveal on screenshot" to highlight element bounds.

- **Story 11: Real-time Appium Integration (MVP Additions)**
  - Per-action timeouts, max retries, and exponential backoff; validate actions via pre/post UI state.
  - Screenshot streaming every 1‚Äì2 seconds with adaptive throttling and fallback to polling on WS drop; stream health indicator in UI.
  - APK install/upgrade policy per run (`noReset`/`fullReset`); post-run cleanup of sessions.

## üñ•Ô∏è **Story 13: Orchestrator API & Session Lifecycle (MVP)**
**Priority**: Must Have | **Sprint**: 4 | **Points**: 8

### Story Description
As a **system**, I want a **minimal orchestrator API** that manages test sessions and streams execution updates so the **UI can control and observe real device runs**.

### Acceptance Criteria
1. Endpoints available:
   - `POST /sessions` creates a session; `POST /runs` starts a run; `GET /runs/:id` gets status.
   - `POST /runs/:id/pause`, `POST /runs/:id/resume`, `POST /runs/:id/abort` control execution (idempotent).
   - `GET /runs/:id/stream` (WS or SSE) streams logs, step updates, and screenshots.
2. Session lifecycle: `idle ‚Üí running ‚Üí paused ‚Üí completed|failed`; invalid state transitions rejected with 409 and structured error.
3. Each response includes `runId` and `correlationId` for UI log linking.
4. Basic rate limiting per user; return 429 with `retryAfterMs`.
5. Secrets are provided via environment variables; never returned to the client.

### Definition of Done
- [ ] API endpoints implement the required lifecycle and control actions
- [ ] Web UI uses `runId` to subscribe to a live stream and control execution
- [ ] JSON error envelope with `code`, `message`, `details`, `correlationId`
- [ ] Basic token header auth enforced for all endpoints (configurable secret)
- [ ] Minimal docs with example requests/responses

---

## üèóÔ∏è **Story 1: Basic UI Framework & Device Management**
**Priority**: Must Have | **Sprint**: 1 | **Points**: 8

### Story Description
As a **manual tester**, I want to **access a web-based interface with emulator view and basic controls** so that I can **start interacting with the AI-QA system and manage test devices**.

### Acceptance Criteria
1. **Given** I open the AI-QA Agent web interface
   **When** the page loads
   **Then** I should see:
   - Left panel (60% width) with black background for emulator display
   - Right panel (40% width) with white background for controls
   - Top toolbar with system title "AI-QA Agent"
   - Bottom status bar showing system information

2. **Given** I am on the main interface
   **When** I look at the top toolbar
   **Then** I should see:
   - Device profile dropdown with options: "Pixel_7_API_33", "Galaxy_S23_API_34", "Nexus_5X_API_30"
   - APK upload button with file selector
   - "Verbose Logging" checkbox toggle
   - Settings gear icon button

3. **Given** I select a different device profile
   **When** I choose "Galaxy_S23_API_34" from dropdown
   **Then** the bottom status bar should update to show "Device: Galaxy_S23_API_34"

4. **Given** I upload an APK file
   **When** I click "Upload APK" and select a .apk file
   **Then** the button text should change to show the filename
   **And** the status bar should show "App: [filename]"

### Technical Implementation Required

#### UI Components Required
```jsx
// Top Toolbar Component
<div className="bg-white border-b border-gray-200 px-4 py-3 flex items-center justify-between">
  <div className="flex items-center space-x-4">
    <h1 className="text-xl font-semibold text-gray-800">AI-QA Agent</h1>
    <div className="flex items-center space-x-2">
      <Smartphone className="w-4 h-4 text-gray-500" />
      <select className="border border-gray-300 rounded px-2 py-1 text-sm">
        <option value="Pixel_7_API_33">Pixel 7 API 33</option>
        <option value="Galaxy_S23_API_34">Galaxy S23 API 34</option>
        <option value="Nexus_5X_API_30">Nexus 5X API 30</option>
      </select>
    </div>
    <div className="flex items-center space-x-2">
      <Upload className="w-4 h-4 text-gray-500" />
      <input type="file" accept=".apk" className="hidden" />
      <label className="cursor-pointer border border-gray-300 rounded px-2 py-1 text-sm bg-gray-50 hover:bg-gray-100">
        Upload APK
      </label>
    </div>
  </div>
  <div className="flex items-center space-x-2">
    <label className="flex items-center space-x-2 text-sm">
      <input type="checkbox" className="rounded" />
      <span>Verbose Logging</span>
    </label>
    <button className="p-2 text-gray-500 hover:text-gray-700">
      <Settings className="w-4 h-4" />
    </button>
  </div>
</div>
```

### Testing Instructions
1. Open web interface in browser
2. Verify all UI elements render correctly
3. Test device dropdown selection
4. Test APK file upload (mock file)
5. Toggle verbose logging checkbox
6. Verify status bar updates

### Definition of Done
- [x] UI renders with specified layout (60/40 split)
- [x] All toolbar controls are functional
- [x] Device selection updates status bar
- [x] File upload shows selected filename
- [x] Responsive design works on desktop browsers
- [x] No console errors in browser dev tools

### ‚úÖ **Story 1 Status: COMPLETED**

**Implementation Summary:**
- React + Vite + TypeScript app scaffolded at `D:\dev\ai-qa-agent\web`
- TailwindCSS v4 configured with PostCSS
- 60/40 layout implemented with emulator mock and console placeholder
- All UI interactions working (device selection, APK upload, verbose toggle)
- Portable Node.js setup working correctly

**To run the development server:**
```powershell
cd "D:\dev\ai-qa-agent\web"
$env:PATH = "D:\tools\node22\node-v22.12.0-win-x64;" + $env:PATH
npm run dev
```

**Verification completed:**
- ‚úÖ Layout renders correctly at http://localhost:5173
- ‚úÖ Device dropdown updates status bar
- ‚úÖ APK upload changes button label and status
- ‚úÖ Responsive design works on desktop
- ‚úÖ No console errors in browser dev tools

---

## üéØ **Story 2: Command Input & Plan Generation Interface**
**Priority**: Must Have | **Sprint**: 1 | **Points**: 5

### Story Description
As a **manual tester**, I want to **input natural language test commands and see generated execution plans** so that I can **review and understand what actions will be performed before execution**.

### Acceptance Criteria
1. **Given** I am on the main interface
   **When** I look at the right panel
   **Then** I should see:
   - Command input section at the top with textarea
   - "Quick Commands" section with 4 predefined commands
   - Plan preview section (appears after command input)

2. **Given** I want to enter a test command
   **When** I click in the textarea
   **Then** I should see placeholder text: "Enter natural language test command..."
   **And** the textarea should accept multi-line input (3 rows)

3. **Given** I see the quick commands section
   **When** I view the available options
   **Then** I should see these clickable commands:
   - "Search for McDonald's and open its page"
   - "Login with valid credentials" 
   - "Add item to cart and checkout"
   - "Navigate to profile settings"

4. **Given** I click a quick command
   **When** I select "Search for McDonald's and open its page"
   **Then** the textarea should populate with that command
   **And** a plan preview should appear below

5. **Given** I have entered a command
   **When** the plan preview is generated
   **Then** I should see:
   - "Generated Plan" heading with confidence score (e.g., "Confidence: 92%")
   - List of 4 planned steps with action types and descriptions
   - Each step showing: action name in blue monospace font + description in gray

### Technical Implementation Required

#### UI Components Required
```jsx
// Command Input Section
<div className="p-4 border-b border-gray-200">
  <div className="space-y-3">
    <label className="block text-sm font-medium text-gray-700">Test Command</label>
    <textarea
      placeholder="Enter natural language test command..."
      className="w-full p-3 border border-gray-300 rounded-lg resize-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
      rows={3}
    />
    
    {/* Quick Commands */}
    <div className="space-y-2">
      <span className="text-xs text-gray-500">Quick Commands:</span>
      <div className="grid gap-1">
        {quickCommands.map((cmd, idx) => (
          <button
            key={idx}
            className="text-left text-xs text-blue-600 hover:text-blue-800 hover:bg-blue-50 p-1 rounded"
          >
            {cmd}
          </button>
        ))}
      </div>
    </div>
  </div>
</div>

// Plan Preview Section
<div className="p-4 border-b border-gray-200 bg-gray-50">
  <div className="space-y-3">
    <div className="flex items-center justify-between">
      <span className="text-sm font-medium text-gray-700">Generated Plan</span>
      <span className="text-xs text-gray-500">Confidence: 92%</span>
    </div>
    
    <div className="space-y-1">
      {generatedPlan.steps.map((step, idx) => (
        <div key={idx} className="text-xs p-2 bg-white rounded border">
          <span className="font-mono text-blue-600">{step.action}</span>
          <span className="ml-2 text-gray-600">{step.description}</span>
        </div>
      ))}
    </div>
  </div>
</div>
```

#### Mock Data for Testing
```javascript
const quickCommands = [
  "Search for McDonald's and open its page",
  "Login with valid credentials",
  "Add item to cart and checkout",
  "Navigate to profile settings"
];

const generatedPlan = {
  app: "in.swiggy.android",
  confidence: 0.92,
  steps: [
    { action: "launch_app", description: "Launch the Swiggy app" },
    { action: "click", description: "Click on search bar" },
    { action: "type", description: "Type search query 'McDonald's'" },
    { action: "click", description: "Select McDonald's from results" }
  ]
};
```

### Testing Instructions
1. Verify textarea renders with correct placeholder
2. Type various commands and verify text input works
3. Click each quick command and verify textarea populates
4. Verify plan preview appears with mock data
5. Check confidence score displays correctly
6. Verify each step shows action type and description

### Definition of Done
- [x] Command input textarea functional with 3-row height
- [x] All 4 quick commands clickable and populate textarea
- [x] Plan preview renders when command is present
- [x] Confidence score displays as percentage
- [x] Plan steps show proper formatting (blue action, gray description)
- [x] Layout matches specified styling

### ‚úÖ **Story 2 Status: COMPLETED**

**Implementation Summary:**
- Command input textarea with proper placeholder and styling
- 4 quick command buttons that populate textarea on click
- Plan preview section with mock data (92% confidence)
- Debounced plan generation (500ms delay)
- Proper step formatting with blue monospace actions and gray descriptions

**Key Features Working:**
- ‚úÖ Textarea accepts multi-line input (3 rows)
- ‚úÖ Quick commands populate textarea and trigger plan preview
- ‚úÖ Plan preview shows/hides based on command content
- ‚úÖ Confidence score displays as percentage (92%)
- ‚úÖ Plan steps formatted correctly (blue action, gray description)
- ‚úÖ Debounced input prevents excessive plan generation

**Verification completed:**
- ‚úÖ All UI components render correctly in right panel
- ‚úÖ Command input and quick commands functional
- ‚úÖ Plan preview appears with mock data
- ‚úÖ Layout and styling match specifications

---

## üì± **Story 3: Emulator Display & Device Simulation**
**Priority**: Must Have | **Sprint**: 2 | **Points**: 8

### Story Description
As a **manual tester**, I want to **see a realistic Android device emulator with app interface** so that I can **visually track test execution and understand the current app state**.

### Acceptance Criteria
1. **Given** I am viewing the main interface
   **When** I look at the left panel (emulator area)
   **Then** I should see:
   - Black background (320x640px centered device frame)
   - Realistic device bezels and physical button representations
   - Android status bar with time "9:41" and signal indicators

2. **Given** the device is displaying an app
   **When** I view the simulated Swiggy app
   **Then** I should see:
   - Blue gradient background (from-blue-500 to-blue-600)
   - "Swiggy" app title in white text
   - Location selector showing "üìç Bengaluru, Karnataka"
   - Search bar with search icon and placeholder
   - Special offers banner placeholder

3. **Given** a test is executing
   **When** I see step "Type 'McDonald's'" is running
   **Then** the search bar input should show "McDonald's" text
   **And** a spinning loading indicator should appear centered on screen

4. **Given** different execution states
   **When** the execution status changes
   **Then** the device display should update:
   - Idle: Clean app interface
   - Running: Loading spinner overlay
   - Input step: Show typed text in relevant fields

### Technical Implementation Required

#### UI Components Required
```jsx
// Emulator Display Component
<div className="w-3/5 bg-black p-4 flex items-center justify-center">
  <div className="relative bg-gray-800 rounded-lg p-6" style={{width: '320px', height: '640px'}}>
    <div className="w-full h-full bg-white rounded flex items-center justify-center relative overflow-hidden">
      {/* Simulated Android Screen */}
      <div className="w-full h-full bg-gradient-to-b from-blue-500 to-blue-600">
        {/* Status Bar */}
        <div className="h-6 bg-black bg-opacity-20 flex items-center justify-between px-2">
          <span className="text-white text-xs">9:41</span>
          <div className="flex space-x-1">
            <div className="w-4 h-2 bg-white rounded-sm opacity-80"></div>
            <div className="w-4 h-2 bg-white rounded-sm opacity-60"></div>
            <div className="w-4 h-2 bg-white rounded-sm opacity-40"></div>
          </div>
        </div>
        
        {/* App Content */}
        <div className="p-4 space-y-4">
          <div className="text-white text-center">
            <h2 className="text-lg font-semibold">Swiggy</h2>
          </div>
          
          {/* Location */}
          <div className="bg-white bg-opacity-20 rounded p-2">
            <span className="text-white text-sm">üìç Bengaluru, Karnataka</span>
          </div>
          
          {/* Search Bar */}
          <div className="bg-white rounded-lg p-3 shadow-lg">
            <div className="flex items-center space-x-2">
              <Search className="w-4 h-4 text-gray-400" />
              <input 
                type="text" 
                placeholder="Search for restaurants"
                className="flex-1 outline-none text-sm"
                value={executionStatus === 'running' && currentStep >= 2 ? "McDonald's" : ""}
                readOnly
              />
            </div>
          </div>
          
          {/* Banner */}
          <div className="bg-white bg-opacity-20 rounded-lg h-20 flex items-center justify-center">
            <span className="text-white text-sm">Special Offers</span>
          </div>
        </div>
        
        {/* Execution Indicator */}
        {executionStatus === 'running' && (
          <div className="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2">
            <div className="w-8 h-8 border-4 border-yellow-400 border-t-transparent rounded-full animate-spin"></div>
          </div>
        )}
      </div>
    </div>
    
    {/* Device Frame */}
    <div className="absolute inset-0 border-8 border-gray-700 rounded-2xl pointer-events-none"></div>
    <div className="absolute top-2 left-1/2 transform -translate-x-1/2 w-12 h-1 bg-gray-600 rounded-full"></div>
    <div className="absolute bottom-2 left-1/2 transform -translate-x-1/2 w-8 h-8 border-2 border-gray-600 rounded-full"></div>
  </div>
</div>
```

#### State Management Required
```javascript
const [executionStatus, setExecutionStatus] = useState('idle'); // idle, running, paused, completed, failed
const [currentStep, setCurrentStep] = useState(0);
```

### Testing Instructions
1. Verify device frame renders with correct dimensions (320x640px)
2. Check Android status bar shows time "9:41" and signal bars
3. Verify Swiggy app interface displays correctly
4. Test execution status changes:
   - Set status to 'running' and verify spinner appears
   - Set currentStep >= 2 and verify search text appears
5. Verify device bezels and home button are visible
6. Check responsive centering in left panel

### Definition of Done
- [ ] Device frame renders with realistic bezels and dimensions
- [ ] Android status bar displays correctly
- [ ] Swiggy app interface matches design
- [ ] Loading spinner shows during execution
- [ ] Search text appears when currentStep >= 2
- [ ] Device is centered in left panel (60% width)
- [ ] All visual elements match specified styling

---

## ‚ö° **Story 4: Execution Controls & Test Management**
**Priority**: Must Have | **Sprint**: 2 | **Points**: 5

### Story Description
As a **manual tester**, I want to **control test execution with start, pause, step, and abort functions** so that I can **manage test runs and debug issues during execution**.

### Acceptance Criteria
1. **Given** I have entered a test command with generated plan
   **When** I look below the plan preview
   **Then** I should see 5 execution control buttons:
   - Green "Start" button with play icon
   - Yellow "Pause" button with pause icon  
   - Blue "Step" button with skip-forward icon
   - Red "Abort" button with square icon
   - Gray "Rerun" button with rotate icon

2. **Given** no command is entered or execution is idle
   **When** I view the control buttons
   **Then** "Start" should be disabled (gray background)
   **And** "Pause", "Step", "Abort" should be disabled
   **And** "Rerun" should be enabled

3. **Given** I click the "Start" button with a valid command
   **When** execution begins
   **Then** the execution status should change to 'running'
   **And** "Start" button should be disabled
   **And** "Pause", "Step", "Abort" buttons should be enabled
   **And** the emulator should show loading spinner

4. **Given** execution is running
   **When** I click "Pause"
   **Then** execution status should change to 'paused'
   **And** "Start" button should be re-enabled (now acts as "Resume")
   **And** loading spinner should disappear

5. **Given** execution is running
   **When** I click "Step"
   **Then** execution should advance one step
   **And** current step counter should increment
   **And** execution should pause automatically

6. **Given** execution is running
   **When** I click "Abort"
   **Then** execution status should change to 'idle'
   **And** all buttons should return to initial state
   **And** current step should reset to 0

### Technical Implementation Required

#### UI Components Required
```jsx
// Execution Controls Component
<div className="flex space-x-2 pt-2">
  <button
    onClick={handleStart}
    disabled={isExecuting || !command}
    className="flex items-center space-x-1 px-3 py-2 bg-green-600 text-white rounded text-sm hover:bg-green-700 disabled:bg-gray-400"
  >
    <Play className="w-3 h-3" />
    <span>Start</span>
  </button>
  
  <button
    disabled={!isExecuting}
    className="flex items-center space-x-1 px-3 py-2 bg-yellow-600 text-white rounded text-sm hover:bg-yellow-700 disabled:bg-gray-400"
  >
    <Pause className="w-3 h-3" />
    <span>Pause</span>
  </button>
  
  <button
    disabled={!isExecuting}
    className="flex items-center space-x-1 px-3 py-2 bg-blue-600 text-white rounded text-sm hover:bg-blue-700 disabled:bg-gray-400"
  >
    <SkipForward className="w-3 h-3" />
    <span>Step</span>
  </button>
  
  <button
    disabled={!isExecuting}
    className="flex items-center space-x-1 px-3 py-2 bg-red-600 text-white rounded text-sm hover:bg-red-700 disabled:bg-gray-400"
  >
    <Square className="w-3 h-3" />
    <span>Abort</span>
  </button>
  
  <button className="flex items-center space-x-1 px-3 py-2 bg-gray-600 text-white rounded text-sm hover:bg-gray-700">
    <RotateCcw className="w-3 h-3" />
    <span>Rerun</span>
  </button>
</div>
```

#### State Management & Handlers Required
```javascript
const [isExecuting, setIsExecuting] = useState(false);
const [executionStatus, setExecutionStatus] = useState('idle');
const [currentStep, setCurrentStep] = useState(0);

const handleStart = () => {
  setIsExecuting(true);
  setExecutionStatus('running');
  // Simulate execution progress
  setTimeout(() => {
    setExecutionStatus('completed');
    setIsExecuting(false);
  }, 5000);
};

const handlePause = () => {
  setExecutionStatus('paused');
  setIsExecuting(false);
};

const handleStep = () => {
  setCurrentStep(prev => prev + 1);
  // Execute single step then pause
};

const handleAbort = () => {
  setExecutionStatus('idle');
  setIsExecuting(false);
  setCurrentStep(0);
};
```

### Testing Instructions
1. Start with no command - verify "Start" is disabled
2. Enter a command - verify "Start" becomes enabled
3. Click "Start" - verify state changes and other buttons enable
4. Test each button function:
   - Start: begins execution
   - Pause: stops execution, allows resume
   - Step: advances one step and pauses
   - Abort: stops and resets everything
   - Rerun: restarts from beginning
5. Verify button states match execution status
6. Check emulator spinner appears/disappears correctly

### Definition of Done
- [x] All 5 control buttons render with correct colors and icons
- [x] Button enable/disable states work correctly
- [x] Start button initiates execution and updates state
- [x] Pause button stops execution and enables resume
- [x] Step button advances execution by one step
- [x] Abort button stops and resets execution
- [x] Rerun button restarts execution from beginning
- [x] Emulator loading indicator syncs with execution state

### ‚úÖ **Story 4 Status: COMPLETED**

**Implementation Summary:**
- Added 5 execution control buttons with proper styling and icons
- Implemented complete state management system for execution control
- Created button handlers for Start/Resume, Pause, Step, Abort, and Rerun
- Added proper button enable/disable logic based on execution state
- Integrated execution controls with emulator display updates
- Added execution status and current step display
- Implemented step-by-step execution with proper state transitions

**Acceptance Criteria Verification:**
‚úÖ All 5 execution control buttons render with correct colors and icons  
‚úÖ Button states properly reflect execution status (idle/running/paused)  
‚úÖ Start button initiates execution and becomes disabled when running  
‚úÖ Pause button stops execution and enables Resume functionality  
‚úÖ Step button advances execution by one step and auto-pauses  
‚úÖ Abort button stops execution and resets to idle state  
‚úÖ Rerun button restarts execution from the beginning  
‚úÖ Emulator loading spinner syncs with execution state

---

## üìä **Story 5: Execution Log & Step Timeline**
**Priority**: Must Have | **Sprint**: 3 | **Points**: 8

### Story Description
As a **manual tester**, I want to **view detailed execution logs with expandable step information** so that I can **track test progress, debug failures, and review execution details**.

### Acceptance Criteria
1. **Given** I am viewing the right panel
   **When** I look at the bottom section
   **Then** I should see 3 tabs:
   - "Execution Log" (active by default)
   - "Inspector" with tree icon
   - "History" with history icon

2. **Given** I am on the Execution Log tab
   **When** execution starts or steps are available
   **Then** I should see a list of execution steps showing:
   - Status icon (green checkmark, red X, blue spinning clock, gray clock)
   - Step description (e.g., "Launch Swiggy app", "Click search bar")
   - Timestamp (e.g., "10:30:45")
   - Duration in parentheses (e.g., "(2.1s)")
   - Camera icon if screenshot available
   - Expand/collapse chevron arrow

3. **Given** I see an execution step
   **When** I click on the step row
   **Then** the step should expand to show:
   - Action type in code format (e.g., `launch_app`)
   - Screenshot view button (if available)
   - "View XML" button for page source
   - Gray background with border separator

4. **Given** I have multiple execution steps
   **When** I view the step list
   **Then** I should see these sample steps:
   - "Launch Swiggy app" - completed, 2.1s duration
   - "Click search bar" - completed, 0.8s duration  
   - "Type 'McDonald's'" - running, 1.2s duration
   - "Select McDonald's from suggestions" - pending, no timestamp

5. **Given** I want to switch between tabs
   **When** I click "Inspector" or "History" tabs
   **Then** the tab should become active (blue border and text)
   **And** the content area should change accordingly

### Technical Implementation Required

#### UI Components Required
```jsx
// Tab Headers
<div className="flex border-b border-gray-200">
  <button 
    onClick={() => setInspectorView('execution')}
    className={`px-4 py-2 text-sm font-medium border-b-2 ${
      inspectorView === 'execution' 
        ? 'border-blue-500 text-blue-600' 
        : 'border-transparent text-gray-500 hover:text-gray-700'
    }`}
  >
    Execution Log
  </button>
  <button 
    onClick={() => setInspectorView('elements')}
    className={`px-4 py-2 text-sm font-medium border-b-2 ${
      inspectorView === 'elements' 
        ? 'border-blue-500 text-blue-600' 
        : 'border-transparent text-gray-500 hover:text-gray-700'
    }`}
  >
    <div className="flex items-center space-x-1">
      <TreePine className="w-4 h-4" />
      <span>Inspector</span>
    </div>
  </button>
  <button 
    onClick={() => setInspectorView('history')}
    className={`px-4 py-2 text-sm font-medium border-b-2 ${
      inspectorView === 'history' 
        ? 'border-blue-500 text-blue-600' 
        : 'border-transparent text-gray-500 hover:text-gray-700'
    }`}
  >
    <div className="flex items-center space-x-1">
      <History className="w-4 h-4" />
      <span>History</span>
    </div>
  </button>
</div>

// Execution Step Component  
<div className="border border-gray-200 rounded-lg">
  <div 
    className="p-3 cursor-pointer hover:bg-gray-50 flex items-center justify-between"
    onClick={() => toggleStepExpansion(step.id)}
  >
    <div className="flex items-center space-x-3">
      {getStatusIcon(step.status)}
      <div>
        <div className="text-sm font-medium">{step.description}</div>
        <div className="text-xs text-gray-500 flex space-x-2">
          <span>{step.timestamp}</span>
          {step.duration && <span>({step.duration})</span>}
        </div>
      </div>
    </div>
    <div className="flex items-center space-x-2">
      {step.screenshot && <Camera className="w-4 h-4 text-gray-400" />}
      {expandedSteps.has(step.id) ? 
        <ChevronDown className="w-4 h-4 text-gray-400" /> :
        <ChevronRight className="w-4 h-4 text-gray-400" />
      }
    </div>
  </div>
  
  {expandedSteps.has(step.id) && (
    <div className="px-3 pb-3 border-t border-gray-100 bg-gray-50">
      <div className="pt-3 space-y-2">
        <div className="text-xs">
          <strong>Action:</strong> <code className="bg-gray-200 px-1 rounded">{step.action}</code>
        </div>
        {step.screenshot && (
          <div className="text-xs">
            <strong>Screenshot:</strong> 
            <button className="ml-2 text-blue-600 hover:text-blue-800">View</button>
          </div>
        )}
        <div className="text-xs">
          <strong>Page Source:</strong> 
          <button className="ml-2 text-blue-600 hover:text-blue-800">View XML</button>
        </div>
      </div>
    </div>
  )}
</div>
```

#### Mock Data Required
```javascript
const executionSteps = [
  {
    id: 1,
    action: 'launch_app',
    description: 'Launch Swiggy app',
    status: 'completed',
    timestamp: '10:30:45',
    screenshot: true,
    duration: '2.1s'
  },
  {
    id: 2,
    action: 'click',
    description: 'Click search bar',
    status: 'completed',
    timestamp: '10:30:47',
    screenshot: true,
    duration: '0.8s'
  },
  {
    id: 3,
    action: 'type',
    description: 'Type "McDonald\'s"',
    status: 'running',
    timestamp: '10:30:48',
    screenshot: false,
    duration: '1.2s'
  },
  {
    id: 4,
    action: 'click',
    description: 'Select McDonald\'s from suggestions',
    status: 'pending',
    timestamp: '',
    screenshot: false,
    duration: ''
  }
];

const getStatusIcon = (status) => {
  switch (status) {
    case 'completed':
      return <CheckCircle className="w-4 h-4 text-green-500" />;
    case 'failed':
      return <XCircle className="w-4 h-4 text-red-500" />;
    case 'running':
      return <Clock className="w-4 h-4 text-blue-500 animate-spin" />;
    default:
      return <Clock className="w-4 h-4 text-gray-400" />;
  }
};
```

### Testing Instructions
1. Verify 3 tabs render with correct icons and labels
2. Check "Execution Log" tab is active by default
3. Verify execution steps display with all required information
4. Test step expansion:
   - Click step to expand
   - Verify expanded content shows
   - Click again to collapse
5. Test status icons for different states
6. Verify camera icon appears only when screenshot available
7. Test tab switching functionality

### Definition of Done
- [x] 3 tabs render with correct styling and icons
- [x] Execution Log tab is active by default
- [x] All execution steps display with proper formatting
- [x] Step expansion/collapse works correctly
- [x] Status icons show correct colors and animations
- [x] Screenshots and page source buttons appear in expanded view
- [x] Tab switching updates active state and content
- [x] Scrollable content area for long execution logs

### ‚úÖ **Story 5 Status: COMPLETED**

**Implementation Summary:**
- Created complete 3-tab interface (Execution Log, Inspector, History)
- Implemented detailed execution step tracking with status management
- Added expandable step details with action codes and artifact buttons
- Integrated step timeline with execution control system
- Added proper status icons with animations (completed, failed, running, pending)
- Implemented tab switching functionality with active state management
- Created scrollable content areas for long execution logs
- Added real-time step progress updates during execution

**Acceptance Criteria Verification:**
‚úÖ 3 tabs render with correct styling and icons (execution, inspector tree, history clock)  
‚úÖ Execution Log tab is active by default with blue highlight  
‚úÖ Execution steps display with proper formatting and timestamps  
‚úÖ Step expansion/collapse works with chevron arrows  
‚úÖ Status icons show correct colors and spinning animations  
‚úÖ Screenshot camera icons and "View XML" buttons appear in expanded steps  
‚úÖ Tab switching properly updates active state and shows/hides content  
‚úÖ Content area is scrollable for handling long execution logs  

---

## ü§ñ **Story 6: LLM Integration & Plan Generation**

### Story Description
As a **manual tester**, I want to **run complete end-to-end automated tests using natural language commands** so that I can **validate the entire AI-QA system works seamlessly from command input to test completion**.

### Acceptance Criteria
1. **Given** I have the complete AI-QA system running
   **When** I perform an end-to-end test
   **Then** the full workflow should execute:
   - Enter natural language command ‚Üí AI generates plan ‚Üí Real device execution ‚Üí Results with screenshots

2. **Given** I want to test a complete user journey
   **When** I enter "Search for McDonald's, add a burger to cart, and proceed to checkout"
   **Then** the system should:
   - Generate a comprehensive multi-step plan using AI
   - Execute each step on real Android emulator via Appium
   - Handle intermediate failures with AI replanning
   - Show live progress with screenshots and logs
   - Provide final pass/fail report with evidence

3. **Given** the system encounters failures during execution
   **When** steps fail (popups, UI changes, network issues)
   **Then** the AI should:
   - Automatically detect and analyze failures
   - Replan with new approach using current UI context
   - Continue execution without manual intervention
   - Log all replanning decisions for debugging

4. **Given** I want to validate system performance
   **When** running multiple test scenarios
   **Then** the system should achieve:
   - 80%+ success rate for simple navigation flows
   - 70%+ success rate for complex multi-step scenarios
   - <10 second average plan generation time
   - <5 second average step execution time

### Integration Test Scenarios

#### Scenario 1: Simple Search Flow
```
Command: "Search for pizza restaurants near me"
Expected AI Plan:
1. launch_app ‚Üí Open Swiggy app
2. click ‚Üí Click search bar (using id="search_bar")
3. type ‚Üí Enter "pizza" text
4. wait_for_element ‚Üí Wait for search results
5. take_screenshot ‚Üí Capture results

Expected Results:
- All steps execute successfully
- Screenshots show actual search results
- No replanning required
- Total execution time <30 seconds
```

#### Scenario 2: Complex E-commerce Flow
```
Command: "Find McDonald's, add a Big Mac to cart, and start checkout"
Expected AI Plan:
1. launch_app ‚Üí Open Swiggy app
2. click ‚Üí Search bar
3. type ‚Üí "McDonald's" 
4. click ‚Üí Select McDonald's restaurant
5. wait_for_element ‚Üí Menu loads
6. click ‚Üí Find Big Mac item
7. click ‚Üí Add to cart button
8. click ‚Üí View cart
9. click ‚Üí Proceed to checkout

Expected Results:
- Multi-step flow executes with 1-2 replanning events
- AI handles menu loading and item selection
- Screenshots show cart and checkout screens
- Total execution time <60 seconds
```

#### Scenario 3: Failure Recovery Flow
```
Command: "Login and update profile information"
Expected Challenges:
- Permission popups during app launch
- OTP verification screens
- Dynamic form fields

Expected AI Behavior:
- Initial plan fails at login step
- AI replans to handle permission popup first
- Adapts to OTP screen with appropriate waits
- Successfully navigates to profile section
- Shows 2-3 replanning events in log
```

### System Performance Validation

#### Success Rate Metrics
```javascript
const performanceTests = [
  {
    category: 'Simple Navigation',
    commands: [
      'Open app settings',
      'Go to profile page',
      'Search for restaurants',
      'View order history'
    ],
    targetSuccessRate: 0.80,
    maxExecutionTime: 30000
  },
  {
    category: 'Form Interactions',
    commands: [
      'Update profile name to John Doe',
      'Change delivery address',
      'Apply promo code SAVE20',
      'Rate last order 5 stars'
    ],
    targetSuccessRate: 0.75,
    maxExecutionTime: 45000
  },
  {
    category: 'Complex Flows',
    commands: [
      'Search for pizza, add 2 items to cart, checkout',
      'Login, browse restaurants, add favorites',
      'Update payment method and place test order'
    ],
    targetSuccessRate: 0.70,
    maxExecutionTime: 90000
  }
];
```

### Technical Integration Requirements

#### Full System Architecture Validation
```javascript
class EndToEndTestRunner {
  constructor() {
    this.llmService = new LLMService();
    this.appiumService = new AppiumService();
    this.replanningService = new ReplanningService(this.llmService);
    this.uiContextService = new UIContextService();
    this.executionEngine = new RealTimeExecutionEngine(
      this.appiumService,
      this.uiContextService,
      this.replanningService
    );
  }
  
  async runEndToEndTest(command, deviceConfig) {
    const testResults = {
      command,
      startTime: Date.now(),
      phases: {}
    };
    
    try {
      // Phase 1: AI Plan Generation
      console.log('Phase 1: Generating AI plan...');
      const planStart = Date.now();
      
      const context = await this.uiContextService.captureInitialContext(deviceConfig);
      const plan = await this.llmService.generatePlan(command, context);
      
      testResults.phases.planGeneration = {
        duration: Date.now() - planStart,
        success: true,
        plan,
        confidence: plan.confidence
      };
      
      // Phase 2: Device Connection & Setup
      console.log('Phase 2: Connecting to device...');
      const connectStart = Date.now();
      
      const connected = await this.appiumService.connect(deviceConfig);
      if (!connected) throw new Error('Device connection failed');
      
      testResults.phases.deviceSetup = {
        duration: Date.now() - connectStart,
        success: true,
        deviceInfo: await this.appiumService.getDeviceInfo()
      };
      
      // Phase 3: Test Execution
      console.log('Phase 3: Executing test plan...');
      const execStart = Date.now();
      
      const executionResult = await this.executionEngine.executeTest(plan, deviceConfig);
      
      testResults.phases.execution = {
        duration: Date.now() - execStart,
        success: executionResult.success,
        results: executionResult.results,
        replanningEvents: executionResult.replanningEvents || []
      };
      
      // Phase 4: Results Collection
      console.log('Phase 4: Collecting results...');
      const screenshots = await this.collectScreenshots(executionResult);
      const finalPageSource = await this.appiumService.getPageSource();
      
      testResults.phases.resultCollection = {
        duration: 500, // Minimal time for collection
        success: true,
        screenshots: screenshots.length,
        finalState: finalPageSource ? 'captured' : 'failed'
      };
      
      // Overall Results
      testResults.endTime = Date.now();
      testResults.totalDuration = testResults.endTime - testResults.startTime;
      testResults.overallSuccess = Object.values(testResults.phases).every(phase => phase.success);
      testResults.replanningCount = testResults.phases.execution.replanningEvents.length;
      
      return testResults;
      
    } catch (error) {
      testResults.endTime = Date.now();
      testResults.totalDuration = testResults.endTime - testResults.startTime;
      testResults.overallSuccess = false;
      testResults.error = error.message;
      
      return testResults;
      
    } finally {
      await this.appiumService.disconnect();
    }
  }
  
  async validatePerformanceMetrics(testResults) {
    const metrics = {
      planGenerationTime: testResults.phases.planGeneration?.duration || 0,
      executionTime: testResults.phases.execution?.duration || 0,
      totalTime: testResults.totalDuration,
      replanningEvents: testResults.replanningCount || 0,
      success: testResults.overallSuccess
    };
    
    // Validate against targets
    const validation = {
      planGenerationSpeed: metrics.planGenerationTime < 10000, // <10s
      executionSpeed: metrics.executionTime < 90000, // <90s for complex flows
      overallTime: metrics.totalTime < 120000, // <2min total
      replanningReasonable: metrics.replanningEvents <= 3, // ‚â§3 replanning events
      successAchieved: metrics.success
    };
    
    return {
      metrics,
      validation,
      passed: Object.values(validation).every(v => v === true)
    };
  }
}
```

#### Integration Test Suite
```javascript
class IntegrationTestSuite {
  constructor() {
    this.testRunner = new EndToEndTestRunner();
    this.results = [];
  }
  
  async runFullTestSuite() {
    const testCases = [
      // Simple flows
      { command: 'Search for pizza restaurants', category: 'simple' },
      { command: 'Open app settings', category: 'simple' },
      { command: 'View my order history', category: 'simple' },
      
      // Medium complexity
      { command: 'Find McDonald\'s and view menu', category: 'medium' },
      { command: 'Add item to favorites', category: 'medium' },
      { command: 'Update delivery address', category: 'medium' },
      
      // Complex flows
      { command: 'Search for pizza, add 2 items to cart, start checkout', category: 'complex' },
      { command: 'Login, browse restaurants, add to favorites', category: 'complex' },
      { command: 'Complete food ordering flow with customization', category: 'complex' }
    ];
    
    const deviceConfig = {
      deviceName: 'Pixel_7_API_33',
      appPath: './test-apps/swiggy.apk'
    };
    
    console.log('Starting integration test suite...');
    
    for (const testCase of testCases) {
      console.log(`Running test: ${testCase.command}`);
      
      try {
        const result = await this.testRunner.runEndToEndTest(testCase.command, deviceConfig);
        const performance = await this.testRunner.validatePerformanceMetrics(result);
        
        this.results.push({
          ...testCase,
          result,
          performance,
          timestamp: new Date().toISOString()
        });
        
        console.log(`‚úì Test completed: ${result.overallSuccess ? 'PASS' : 'FAIL'}`);
        
      } catch (error) {
        console.error(`‚úó Test failed: ${error.message}`);
        this.results.push({
          ...testCase,
          result: { overallSuccess: false, error: error.message },
          performance: { passed: false },
          timestamp: new Date().toISOString()
        });
      }
      
      // Wait between tests
      await this.delay(5000);
    }
    
    return this.generateReport();
  }
  
  generateReport() {
    const summary = {
      totalTests: this.results.length,
      passed: this.results.filter(r => r.result.overallSuccess).length,
      failed: this.results.filter(r => !r.result.overallSuccess).length,
      categories: {}
    };
    
    // Category breakdown
    ['simple', 'medium', 'complex'].forEach(category => {
      const categoryTests = this.results.filter(r => r.category === category);
      summary.categories[category] = {
        total: categoryTests.length,
        passed: categoryTests.filter(r => r.result.overallSuccess).length,
        successRate: categoryTests.length > 0 ? 
          categoryTests.filter(r => r.result.overallSuccess).length / categoryTests.length : 0
      };
    });
    
    return {
      summary,
      detailedResults: this.results,
      overallSuccessRate: summary.passed / summary.totalTests,
      recommendations: this.generateRecommendations(summary)
    };
  }
  
  generateRecommendations(summary) {
    const recommendations = [];
    
    if (summary.categories.simple.successRate < 0.8) {
      recommendations.push('Simple navigation flows need improvement - check element selectors');
    }
    
    if (summary.categories.complex.successRate < 0.7) {
      recommendations.push('Complex flows need better replanning logic');
    }
    
    const avgReplanningEvents = this.results.reduce((sum, r) => 
      sum + (r.result.replanningCount || 0), 0) / this.results.length;
      
    if (avgReplanningEvents > 2) {
      recommendations.push('High replanning frequency - improve initial plan quality');
    }
    
    return recommendations;
  }
  
  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

### Testing Instructions

#### Prerequisites Setup
1. **Environment Setup**:
   ```bash
   # Start Appium server
   appium --port 4723
   
   # Launch Android emulator
   emulator -avd Pixel_7_API_33
   
   # Install test APK
   adb install test-apps/swiggy.apk
   ```

2. **System Configuration**:
   - Configure LLM API keys (OpenAI/Claude)
   - Verify all services are running
   - Check device connectivity

#### Manual Test Execution
1. **Simple Flow Test**:
   - Enter: "Search for McDonald's restaurants"
   - Expected: 4-step plan, successful execution, <30s duration
   - Validate: Screenshots show search results

2. **Complex Flow Test**:
   - Enter: "Find pizza restaurants, add margherita to cart"
   - Expected: 8+ step plan, 1-2 replanning events, <90s duration
   - Validate: Cart shows selected item

3. **Failure Recovery Test**:
   - Simulate failures: disconnect network during execution
   - Expected: AI detects failures and replans appropriately
   - Validate: Execution continues after network restoration

#### Automated Test Suite
1. Run integration test suite:
   ```javascript
   const suite = new IntegrationTestSuite();
   const report = await suite.runFullTestSuite();
   console.log('Test Report:', report);
   ```

2. Validate success rates:
   - Simple flows: >80% success rate
   - Medium flows: >75% success rate
   - Complex flows: >70% success rate

### Definition of Done
- [ ] Complete end-to-end workflow executes: Command ‚Üí AI Plan ‚Üí Real Execution ‚Üí Results
- [ ] Integration test suite passes with target success rates (80%/75%/70%)
- [ ] AI replanning works automatically for real device failures
- [ ] Performance metrics meet targets (<10s planning, <90s execution)
- [ ] Live screenshot streaming shows actual device state
- [ ] Comprehensive test reports generated with screenshots and logs
- [ ] System handles edge cases (network issues, popups, UI changes)
- [ ] Manual testers can successfully run tests without technical knowledge

---

## ÔøΩ **Success Metrics & Performance Targets**

### **MVP Success Criteria**
‚úÖ **Technical Success**: 80% success rate on simple flows, visual execution tracking, AI-powered replanning  
‚úÖ **User Experience**: Manual testers can create automated tests using natural language  
‚úÖ **AI Performance**: Intelligent plan generation, self-healing tests, continuous learning  
‚úÖ **Integration**: Real Appium integration, live device control, comprehensive logging  

### **Performance Benchmarks**
- **Plan Generation**: <10 seconds average response time
- **Step Execution**: <5 seconds average per action
- **Simple Flows**: 80%+ success rate (navigation, search, basic interactions)
- **Medium Flows**: 75%+ success rate (forms, multi-step processes)
- **Complex Flows**: 70%+ success rate (e-commerce, authentication with OTP)
- **Replanning Success**: 60%+ recovery rate from initial failures

### **Quality Gates**
- **Code Coverage**: >85% for core components
- **UI Responsiveness**: <100ms for all user interactions
- **Memory Usage**: <500MB peak during test execution
- **API Response Time**: <3 seconds for LLM plan generation
- **Device Connection**: <30 seconds to establish Appium connection

---

## üöÄ **Implementation Roadmap**

### **Phase 1: Foundation (Sprints 1-2) - 4 weeks**
**Goal**: Basic functional interface with device simulation
- ‚úÖ UI Framework with emulator display
- ‚úÖ Command input and basic plan preview
- ‚úÖ Execution controls and state management
- ‚úÖ Device selection and APK upload mockups

### **Phase 2: Intelligence (Sprints 3-4) - 4 weeks**  
**Goal**: AI integration and intelligent plan generation
- ‚úÖ LLM API integration with plan generation
- ‚úÖ UI context collection and element analysis
- ‚úÖ Execution logging with detailed step timeline
- ‚úÖ Element inspector and UI tree display

### **Phase 3: Self-Healing (Sprints 5-6) - 4 weeks**
**Goal**: Advanced AI capabilities and learning
- ‚úÖ AI-powered replanning and failure recovery
- ‚úÖ Few-shot learning and advanced prompting
- ‚úÖ Knowledge base and pattern recognition
- ‚úÖ Chain-of-thought reasoning for complex scenarios

### **Phase 4: Real Execution (Sprints 7-8) - 4 weeks**
**Goal**: Live device control and end-to-end automation
- ‚úÖ Appium integration and WebDriver control
- ‚úÖ Real-time screenshot streaming
- ‚úÖ Live test execution on Android emulators
- ‚úÖ Complete system validation and performance testing

---

## üß™ **Testing Strategy**

### **Unit Testing** (per sprint)
- Component-level React testing with Jest/RTL
- Service layer testing for LLM integration
- Appium action execution validation
- State management and UI interaction testing

### **Integration Testing** (sprint 4, 6, 8)
- LLM API integration with real/mock responses
- Appium server connectivity and device management
- End-to-end workflow testing with sample apps
- Cross-browser compatibility testing

### **System Testing** (sprint 8)
- Full workflow automation: Command ‚Üí Plan ‚Üí Execute ‚Üí Report
- Performance testing under load (multiple concurrent tests)
- Failure scenario testing (network issues, device disconnects)
- User acceptance testing with manual testers

### **Test Applications**
- **Simple App**: Basic navigation and input forms
- **Swiggy/Food Delivery**: Complex e-commerce flows with search, cart, checkout
- **Banking App**: Authentication flows with OTP and security
- **Social Media**: Content creation, sharing, and interaction flows

---

## üîß **Technical Architecture Summary**

### **Frontend Stack**
- **React 18**: Component-based UI with hooks for state management
- **TailwindCSS**: Utility-first styling for responsive design
- **Lucide Icons**: Consistent iconography throughout the interface
- **WebSocket**: Real-time communication for live execution updates

### **Backend Services**
- **FastAPI/Node.js**: RESTful APIs for plan generation and execution control
- **LLM Integration**: OpenAI/Claude APIs for intelligent plan generation
- **Appium Server**: WebDriver protocol for Android device automation
- **PostgreSQL**: Execution logs, test history, and knowledge base storage

### **AI/ML Components**
- **Prompt Engineering**: Few-shot learning with domain-specific examples
- **Context Processing**: UI element prioritization and OCR integration
- **Replanning Engine**: Failure detection and adaptive test recovery
- **Knowledge Base**: Pattern recognition and element reliability scoring

### **DevOps & Infrastructure**
- **Docker**: Containerized deployment for consistent environments
- **CI/CD Pipeline**: Automated testing and deployment with GitHub Actions
- **Monitoring**: Real-time system health and performance metrics
- **Documentation**: Comprehensive API docs and user guides

---

## üí° **Innovation Highlights**

### **AI-First Approach**
- **Natural Language Processing**: Convert human intent to executable test plans
- **Visual Understanding**: OCR and screenshot analysis for context-aware decisions
- **Self-Healing Tests**: Automatic recovery from failures without human intervention
- **Continuous Learning**: Improve accuracy over time through execution feedback

### **Real-Time Collaboration**
- **Live Execution Monitoring**: Watch tests run in real-time with visual feedback
- **Interactive Debugging**: Step-by-step execution with pause/resume capabilities
- **Element Inspector**: Deep dive into UI structure for troubleshooting
- **Comprehensive Logging**: Detailed audit trail for compliance and debugging

### **Accessibility & Usability**
- **No-Code Automation**: Enable manual testers to create automation without programming
- **Visual Test Creation**: Point-and-click interface with drag-and-drop simplicity
- **Multi-Device Support**: Test across different Android device profiles
- **Export Capabilities**: Generate reusable test scripts and reports

---

This **AI-QA Agent** represents a significant advancement in mobile test automation, combining the power of large language models with real device execution to create a truly intelligent testing platform that adapts, learns, and evolves with your applications! üéâ
**Priority**: Should Have | **Sprint**: 6 | **Points**: 8

### Story Description
As a **system**, I want to **use advanced AI prompting techniques and few-shot learning** so that the **LLM generates more accurate and context-aware test plans with improved success rates**.

### Acceptance Criteria
1. **Given** the system needs to improve LLM accuracy
   **When** generating test plans
   **Then** the system should use:
   - Few-shot prompting with 3-5 example scenarios per app
   - Chain-of-thought reasoning for complex multi-step flows
   - App-specific context and common patterns
   - Domain knowledge about mobile UI conventions

2. **Given** different types of test scenarios
   **When** the AI processes commands
   **Then** it should use specialized prompts for:
   - Authentication flows (login, signup, logout)
   - E-commerce flows (search, add to cart, checkout)
   - Navigation flows (menu navigation, deep linking)
   - Form interactions (input validation, submission)

3. **Given** the system learns from execution history
   **When** generating new plans
   **Then** it should:
   - Reference successful patterns from previous executions
   - Avoid element selectors that frequently fail
   - Adapt to app-specific UI conventions
   - Build knowledge base of working solutions

4. **Given** complex multi-step scenarios
   **When** processing commands like "Complete food ordering flow"
   **Then** the AI should:
   - Break down into logical sub-goals
   - Show reasoning for each step decision
   - Handle dependencies between steps
   - Plan for common error scenarios

### Technical Implementation Required

#### Few-Shot Prompting Templates
```javascript
class AdvancedPromptService {
  constructor() {
    this.fewShotExamples = {
      'search_flow': [
        {
          command: "Search for pizza restaurants",
          context: { app: "swiggy", elements: ["search_bar", "location"] },
          plan: {
            steps: [
              { action: "click", selector: "search_bar", description: "Click search input" },
              { action: "type", text: "pizza", description: "Type search query" },
              { action: "wait_for_element", selector: "search_results", description: "Wait for results" }
            ],
            reasoning: "Search flow requires input focus, text entry, and result loading"
          }
        },
        {
          command: "Find McDonald's near me",
          context: { app: "swiggy", elements: ["search_bar", "filters"] },
          plan: {
            steps: [
              { action: "click", selector: "search_bar" },
              { action: "type", text: "McDonald's" },
              { action: "click", selector: "//TextView[contains(@text, 'McDonald')]" }
            ],
            reasoning: "Brand search can use text matching for restaurant selection"
          }
        }
      ],
      'auth_flow': [
        {
          command: "Login with test credentials",
          context: { app: "swiggy", elements: ["login_button", "phone_input"] },
          plan: {
            steps: [
              { action: "click", selector: "login_button", description: "Open login screen" },
              { action: "type", selector: "phone_input", text: "+911234567890", description: "Enter phone" },
              { action: "click", selector: "continue_button", description: "Proceed to OTP" }
            ],
            reasoning: "Login flow typically requires navigation to auth screen then credential entry"
          }
        }
      ]
    };
  }
  
  buildFewShotPrompt(command, context) {
    const flowType = this.detectFlowType(command);
    const examples = this.fewShotExamples[flowType] || [];
    
    return `
System: You are an expert mobile test automation specialist. Generate precise test plans using the patterns shown below.

${examples.map(ex => `
Example:
Command: "${ex.command}"
Context: ${JSON.stringify(ex.context)}
Plan: ${JSON.stringify(ex.plan)}
Reasoning: ${ex.plan.reasoning}
`).join('\n')}

Now generate a plan for:
Command: "${command}"
Context: ${JSON.stringify(context)}

Think step by step:
1. What is the user's goal?
2. What UI elements are needed?
3. What's the logical sequence?
4. What could go wrong?

Response format:
{
  "reasoning": "Step-by-step thinking about the approach",
  "confidence": 0.85,
  "plan": {
    "steps": [...],
    "anticipated_issues": ["possible problems"],
    "fallback_strategies": ["alternative approaches"]
  }
}`;
  }
  
  detectFlowType(command) {
    const patterns = {
      'search_flow': /search|find|look for/i,
      'auth_flow': /login|signup|authenticate|sign in/i,
      'ecommerce_flow': /add to cart|checkout|purchase|buy/i,
      'navigation_flow': /go to|navigate|open|menu/i
    };
    
    for (const [type, pattern] of Object.entries(patterns)) {
      if (pattern.test(command)) return type;
    }
    
    return 'general_flow';
  }
}
```

#### Knowledge Base & Learning System
```javascript
class TestKnowledgeBase {
  constructor() {
    this.successPatterns = new Map();
    this.failurePatterns = new Map();
    this.elementReliability = new Map();
  }
  
  recordExecution(command, plan, result) {
    const pattern = {
      command: this.normalizeCommand(command),
      selectors: plan.steps.map(s => s.selector).filter(Boolean),
      success: result.success,
      failureReason: result.error,
      timestamp: Date.now()
    };
    
    if (result.success) {
      this.recordSuccess(pattern);
    } else {
      this.recordFailure(pattern);
    }
    
    // Update element reliability scores
    this.updateElementReliability(plan.steps, result);
  }
  
  recordSuccess(pattern) {
    const key = pattern.command;
    if (!this.successPatterns.has(key)) {
      this.successPatterns.set(key, []);
    }
    this.successPatterns.get(key).push(pattern);
  }
  
  getSuccessfulPatterns(command) {
    const normalizedCommand = this.normalizeCommand(command);
    return this.successPatterns.get(normalizedCommand) || [];
  }
  
  getElementReliability(selector) {
    const stats = this.elementReliability.get(selector);
    if (!stats) return 0.5; // Default neutral score
    
    return stats.successes / (stats.successes + stats.failures);
  }
  
  generateKnowledgePrompt(command) {
    const successfulPatterns = this.getSuccessfulPatterns(command);
    const reliableSelectors = Array.from(this.elementReliability.entries())
      .filter(([_, stats]) => stats.successes > 2 && stats.successes / (stats.successes + stats.failures) > 0.8)
      .map(([selector, stats]) => ({ selector, reliability: stats.successes / (stats.successes + stats.failures) }));
    
    return `
Historical Context:
Successful patterns for similar commands:
${JSON.stringify(successfulPatterns.slice(-3), null, 2)}

Reliable selectors (>80% success rate):
${JSON.stringify(reliableSelectors, null, 2)}

Prefer reliable selectors and proven patterns when possible.
`;
  }
}
```

#### Chain-of-Thought Reasoning
```javascript
class ChainOfThoughtService {
  async generatePlanWithReasoning(command, context, knowledgeBase) {
    const prompt = `
You are planning a mobile test. Think through this step by step.

Command: "${command}"
Available UI Elements: ${JSON.stringify(context.elements.slice(0, 10))}
${knowledgeBase.generateKnowledgePrompt(command)}

Step 1: Goal Analysis
What is the user trying to accomplish?

Step 2: UI Analysis  
Which elements are relevant? What's their purpose?

Step 3: Flow Planning
What's the logical sequence of actions?

Step 4: Risk Assessment
What could go wrong? How to handle it?

Step 5: Final Plan
Based on the above analysis, generate the test plan:

{
  "goal_analysis": "User wants to...",
  "relevant_elements": ["element1", "element2"],
  "reasoning_steps": [
    "First I need to...",
    "Then I should...",
    "Finally..."
  ],
  "risk_factors": ["Popup might appear", "Loading time variable"],
  "mitigation_strategies": ["Add waits", "Handle popups"],
  "final_plan": {
    "confidence": 0.85,
    "steps": [...]
  }
}`;

    return await this.llmService.generateWithReasoning(prompt);
  }
}
```

#### Adaptive Learning Integration
```javascript
class AdaptiveLearningService {
  constructor(knowledgeBase, promptService) {
    this.knowledgeBase = knowledgeBase;
    this.promptService = promptService;
  }
  
  async generateAdaptivePlan(command, context) {
    // Get historical knowledge
    const knowledge = this.knowledgeBase.generateKnowledgePrompt(command);
    
    // Build prompt with few-shot examples and knowledge
    const basePrompt = this.promptService.buildFewShotPrompt(command, context);
    const enhancedPrompt = `${basePrompt}\n\n${knowledge}`;
    
    // Generate plan with reasoning
    const result = await this.chainOfThought.generatePlanWithReasoning(
      command, 
      context, 
      this.knowledgeBase
    );
    
    // Post-process to adjust based on element reliability
    return this.adjustForReliability(result, context);
  }
  
  adjustForReliability(plan, context) {
    // Replace unreliable selectors with more reliable alternatives
    plan.steps = plan.steps.map(step => {
      if (step.selector) {
        const reliability = this.knowledgeBase.getElementReliability(step.selector);
        if (reliability < 0.6) {
          // Find alternative selector
          const alternatives = this.findAlternativeSelectors(step.selector, context.elements);
          if (alternatives.length > 0) {
            step.selector = alternatives[0].selector;
            step.confidence_adjustment = -0.1; // Lower confidence for fallback
          }
        }
      }
      return step;
    });
    
    return plan;
  }
}
```

### Testing Instructions
1. **Test Few-Shot Learning**:
   - Verify examples are included in prompts for different flow types
   - Test pattern detection for search, auth, ecommerce flows
   - Check that examples improve plan accuracy
2. **Test Knowledge Base**:
   - Record successful and failed executions
   - Verify element reliability scoring
   - Test knowledge retrieval for similar commands
3. **Test Chain-of-Thought**:
   - Verify reasoning steps in generated plans
   - Check goal analysis and risk assessment
   - Test complex multi-step scenario handling
4. **Test Adaptive Learning**:
   - Verify unreliable selectors are replaced
   - Test improvement over time with usage
   - Check confidence adjustments for fallback selectors

### Definition of Done
- [ ] Few-shot prompting templates for major flow types (search, auth, ecommerce, navigation)
- [ ] Knowledge base records execution patterns and element reliability
- [ ] Chain-of-thought reasoning shows step-by-step plan development
- [ ] Adaptive learning improves selector choices based on historical success
- [ ] Pattern detection automatically categorizes commands by flow type
- [ ] Historical context influences new plan generation
- [ ] Element reliability scoring guides selector preferences
- [ ] Complex scenarios broken down into logical sub-goals

---

## Story 11: Real-time Appium Integration & Device Control
**Priority**: Must Have | **Sprint**: 7 | **Points**: 13

### Story Description
As a **manual tester**, I want the **system to connect to real Android emulators via Appium and execute AI-generated test steps** so that I can **run actual automated tests on live applications**.

### Acceptance Criteria
1. **Given** I have selected a device and uploaded an APK
   **When** I start test execution
   **Then** the system should:
   - Connect to Appium server running locally
   - Launch the specified APK on the selected emulator
   - Stream live screenshots to the web interface
   - Execute each test step via Appium WebDriver

2. **Given** a test step needs to be executed
   **When** the AI generates an action like `{"action": "click", "by": "id", "selector": "search_bar"}`
   **Then** the system should:
   - Translate the action to Appium WebDriver command
   - Execute: `driver.find_element(By.ID, "search_bar").click()`
   - Capture screenshot after execution
   - Validate the action succeeded
   - Update UI with real execution status

3. **Given** I want to see live emulator feed
   **When** execution is running
   **Then** I should see:
   - Real-time screenshots from the actual device
   - Updates every 1-2 seconds during execution
   - Actual app state changes as steps execute
   - Loading indicators synced with real execution

4. **Given** different types of actions in the plan
   **When** executing the test steps
   **Then** the system should support:
   - `launch_app`: Install and launch APK
   - `click`: Element clicking with wait and retry
   - `type`: Text input with keyboard handling
   - `swipe`: Touch gestures and scrolling
   - `wait_for_element`: Explicit waits with timeouts
   - `take_screenshot`: Screenshot capture
   - `back`: Android back button press

5. **Given** real execution may encounter errors
   **When** steps fail (element not found, timeout, etc.)
   **Then** the system should:
   - Capture error details and screenshot
   - Trigger AI replanning with real failure context
   - Continue with replanned steps
   - Show actual failure reasons in execution log

### Technical Implementation Required

#### Appium WebDriver Service
```javascript
const { Builder, By, until } = require('selenium-webdriver');
require('appium-flutter-driver');

class AppiumService {
  constructor() {
    this.driver = null;
    this.isConnected = false;
  }
  
  async connect(deviceConfig) {
    const capabilities = {
      platformName: 'Android',
      deviceName: deviceConfig.deviceName,
      app: deviceConfig.appPath,
      automationName: 'UiAutomator2',
      newCommandTimeout: 300,
      noReset: false,
      fullReset: false
    };
    
    try {
      this.driver = await new Builder()
        .usingServer('http://localhost:4723/wd/hub')
        .withCapabilities(capabilities)
        .build();
        
      this.isConnected = true;
      console.log(`Connected to device: ${deviceConfig.deviceName}`);
      return true;
      
    } catch (error) {
      console.error('Appium connection failed:', error);
      this.isConnected = false;
      return false;
    }
  }
  
  async executeAction(action) {
    if (!this.isConnected) {
      throw new Error('Not connected to Appium server');
    }
    
    const startTime = Date.now();
    let result;
    
    try {
      switch (action.action) {
        case 'launch_app':
          result = await this.launchApp();
          break;
          
        case 'click':
          result = await this.clickElement(action);
          break;
          
        case 'type':
          result = await this.typeText(action);
          break;
          
        case 'swipe':
          result = await this.swipeGesture(action);
          break;
          
        case 'wait_for_element':
          result = await this.waitForElement(action);
          break;
          
        case 'take_screenshot':
          result = await this.takeScreenshot();
          break;
          
        case 'back':
          result = await this.pressBack();
          break;
          
        default:
          throw new Error(`Unsupported action: ${action.action}`);
      }
      
      const endTime = Date.now();
      const screenshot = await this.takeScreenshot();
      
      return {
        success: true,
        result,
        duration: endTime - startTime,
        screenshot: screenshot,
        timestamp: new Date().toISOString()
      };
      
    } catch (error) {
      const endTime = Date.now();
      const screenshot = await this.takeScreenshot();
      
      return {
        success: false,
        error: error.message,
        duration: endTime - startTime,
        screenshot: screenshot,
        timestamp: new Date().toISOString()
      };
    }
  }
  
  async clickElement(action) {
    const element = await this.findElement(action);
    
    // Wait for element to be clickable
    await this.driver.wait(until.elementIsEnabled(element), 10000);
    
    await element.click();
    return { action: 'click', selector: action.selector };
  }
  
  async typeText(action) {
    const element = await this.findElement(action);
    
    // Clear existing text if needed
    await element.clear();
    await element.sendKeys(action.text);
    
    return { action: 'type', text: action.text };
  }
  
  async findElement(action) {
    const { by, selector } = action;
    let locator;
    
    switch (by) {
      case 'id':
        locator = By.id(selector);
        break;
      case 'xpath':
        locator = By.xpath(selector);
        break;
      case 'class':
        locator = By.className(selector);
        break;
      case 'text':
        locator = By.xpath(`//*[@text="${selector}"]`);
        break;
      case 'accessibility':
        locator = By.xpath(`//*[@content-desc="${selector}"]`);
        break;
      default:
        throw new Error(`Unsupported selector type: ${by}`);
    }
    
    // Wait for element with timeout
    const element = await this.driver.wait(until.elementLocated(locator), 10000);
    return element;
  }
  
  async takeScreenshot() {
    if (!this.isConnected) return null;
    
    const screenshot = await this.driver.takeScreenshot();
    return screenshot; // Base64 encoded image
  }
  
  async getPageSource() {
    if (!this.isConnected) return null;
    
    return await this.driver.getPageSource();
  }
  
  async getCurrentActivity() {
    if (!this.isConnected) return null;
    
    return await this.driver.getCurrentActivity();
  }
  
  async disconnect() {
    if (this.driver) {
      await this.driver.quit();
      this.isConnected = false;
    }
  }
}
```

#### Real-time Execution Engine
```javascript
class RealTimeExecutionEngine {
  constructor(appiumService, uiContextService, replanningService) {
    this.appium = appiumService;
    this.uiContext = uiContextService;
    this.replanning = replanningService;
    this.screenshotInterval = null;
  }
  
  async executeTest(plan, deviceConfig) {
    // Connect to device
    const connected = await this.appium.connect(deviceConfig);
    if (!connected) {
      throw new Error('Failed to connect to Appium server');
    }
    
    // Start live screenshot streaming
    this.startScreenshotStream();
    
    try {
      const results = [];
      
      for (let i = 0; i < plan.steps.length; i++) {
        const step = plan.steps[i];
        console.log(`Executing step ${i + 1}: ${step.description}`);
        
        // Update UI with current step
        this.emit('stepStarted', { stepIndex: i, step });
        
        // Execute the step
        const result = await this.executeStepWithRetry(step, i, plan);
        
        if (!result.success) {
          // Attempt replanning
          const replanResult = await this.attemptReplanning(plan, i, result);
          
          if (replanResult.success) {
            // Update plan and continue
            plan.steps = replanResult.newSteps;
            continue;
          } else {
            // Stop execution on failure
            results.push({ ...result, stepIndex: i });
            break;
          }
        }
        
        results.push({ ...result, stepIndex: i });
        
        // Update UI with step completion
        this.emit('stepCompleted', { stepIndex: i, result });
        
        // Small delay between steps
        await this.delay(1000);
      }
      
      return {
        success: results.every(r => r.success),
        results,
        totalSteps: results.length
      };
      
    } finally {
      this.stopScreenshotStream();
      await this.appium.disconnect();
    }
  }
  
  async executeStepWithRetry(step, stepIndex, plan, maxRetries = 2) {
    let lastError;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        // Capture UI context before execution
        const beforeContext = await this.uiContext.captureContext(this.appium.driver);
        
        // Execute the step
        const result = await this.appium.executeAction(step);
        
        if (result.success) {
          // Validate the result
          const afterContext = await this.uiContext.captureContext(this.appium.driver);
          const isValid = await this.validateStepResult(step, beforeContext, afterContext);
          
          if (isValid) {
            return result;
          } else {
            throw new Error('Step validation failed - expected result not achieved');
          }
        } else {
          throw new Error(result.error);
        }
        
      } catch (error) {
        console.warn(`Step ${stepIndex} attempt ${attempt + 1} failed:`, error.message);
        lastError = error;
        
        if (attempt < maxRetries) {
          await this.delay(2000); // Wait before retry
        }
      }
    }
    
    return {
      success: false,
      error: lastError.message,
      stepIndex,
      retryCount: maxRetries
    };
  }
  
  async attemptReplanning(originalPlan, failedStepIndex, failure) {
    const currentContext = await this.uiContext.captureContext(this.appium.driver);
    
    const replanResult = await this.replanning.handleFailure(
      originalPlan.originalGoal,
      originalPlan.steps[failedStepIndex],
      {
        currentUI: currentContext,
        error: failure.error,
        stepHistory: originalPlan.steps.slice(0, failedStepIndex),
        attemptCount: 1
      }
    );
    
    if (replanResult.success) {
      // Insert new steps into plan
      const newSteps = [
        ...originalPlan.steps.slice(0, failedStepIndex),
        ...replanResult.newPlan.corrected_steps,
        ...originalPlan.steps.slice(failedStepIndex + 1)
      ];
      
      return { success: true, newSteps };
    }
    
    return { success: false, reason: replanResult.reason };
  }
  
  startScreenshotStream() {
    this.screenshotInterval = setInterval(async () => {
      try {
        const screenshot = await this.appium.takeScreenshot();
        this.emit('screenshotUpdate', { screenshot, timestamp: Date.now() });
      } catch (error) {
        console.error('Screenshot capture failed:', error);
      }
    }, 2000); // Update every 2 seconds
  }
  
  stopScreenshotStream() {
    if (this.screenshotInterval) {
      clearInterval(this.screenshotInterval);
      this.screenshotInterval = null;
    }
  }
  
  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

#### Frontend Integration for Real Execution
```javascript
const RealTimeExecution = () => {
  const [liveScreenshot, setLiveScreenshot] = useState(null);
  const [executionEngine] = useState(new RealTimeExecutionEngine());
  
  useEffect(() => {
    // Listen for real-time events
    executionEngine.on('screenshotUpdate', ({ screenshot }) => {
      setLiveScreenshot(`data:image/png;base64,${screenshot}`);
    });
    
    executionEngine.on('stepStarted', ({ stepIndex, step }) => {
      setCurrentStep(stepIndex);
      setExecutionStatus('running');
    });
    
    executionEngine.on('stepCompleted', ({ stepIndex, result }) => {
      updateExecutionLog(stepIndex, result);
    });
    
    return () => {
      executionEngine.removeAllListeners();
    };
  }, []);
  
  const handleRealExecution = async () => {
    const deviceConfig = {
      deviceName: selectedDevice,
      appPath: selectedApp
    };
    
    try {
      setIsExecuting(true);
      const results = await executionEngine.executeTest(generatedPlan, deviceConfig);
      
      setExecutionStatus(results.success ? 'completed' : 'failed');
    } catch (error) {
      setExecutionStatus('failed');
      console.error('Execution failed:', error);
    } finally {
      setIsExecuting(false);
    }
  };
  
  return (
    <div className="emulator-display">
      {liveScreenshot ? (
        <img 
          src={liveScreenshot} 
          alt="Live emulator feed"
          className="w-full h-full object-contain"
        />
      ) : (
        <div className="flex items-center justify-center h-full">
          <span className="text-gray-500">Connecting to device...</span>
        </div>
      )}
    </div>
  );
};
```

### Testing Instructions
1. **Setup Appium Environment**:
   - Install Appium server (`npm install -g appium`)
   - Start Appium server on localhost:4723
   - Setup Android emulator or connect real device
2. **Test Device Connection**:
   - Verify connection to Appium server
   - Test APK installation and launch
   - Check screenshot capture functionality
3. **Test Action Execution**:
   - Test each supported action type (click, type, swipe, etc.)
   - Verify element finding with different selector strategies
   - Test error handling for element not found scenarios
4. **Test Real-time Features**:
   - Verify live screenshot streaming
   - Test execution status updates
   - Check real failure detection and replanning
5. **Integration Testing**:
   - Run end-to-end test with AI plan generation + real execution
   - Test replanning with actual device failures
   - Verify UI updates reflect real device state

### Definition of Done
- [ ] Appium WebDriver service connects to local Appium server
- [ ] All major action types supported (click, type, swipe, wait, screenshot)
- [ ] Real-time screenshot streaming to web interface
- [ ] Live execution status updates in UI
- [ ] Element finding with multiple selector strategies
- [ ] Error handling and retry logic for transient failures
- [ ] Integration with AI replanning for real device failures
- [ ] APK installation and app launching functionality
- [ ] Graceful disconnect and cleanup on test completion# AI-QA Agent User Stories

## Epic: AI-Powered Mobile Test Automation Platform

**Vision**: Enable manual testers to automate repetitive test cases using natural language commands with minimal scripting knowledge.

---

## Story 1: Basic UI Framework & Device Management
**Priority**: Must Have | **Sprint**: 1 | **Points**: 8

### Story Description
As a **manual tester**, I want to **access a web-based interface with emulator view and basic controls** so that I can **start interacting with the AI-QA system and manage test devices**.

### Acceptance Criteria
1. **Given** I open the AI-QA Agent web interface
   **When** the page loads
   **Then** I should see:
   - Left panel (60% width) with black background for emulator display
   - Right panel (40% width) with white background for controls
   - Top toolbar with system title "AI-QA Agent"
   - Bottom status bar showing system information

2. **Given** I am on the main interface
   **When** I look at the top toolbar
   **Then** I should see:
   - Device profile dropdown with options: "Pixel_7_API_33", "Galaxy_S23_API_34", "Nexus_5X_API_30"
   - APK upload button with file selector
   - "Verbose Logging" checkbox toggle
   - Settings gear icon button

3. **Given** I select a different device profile
   **When** I choose "Galaxy_S23_API_34" from dropdown
   **Then** the bottom status bar should update to show "Device: Galaxy_S23_API_34"

4. **Given** I upload an APK file
   **When** I click "Upload APK" and select a .apk file
   **Then** the button text should change to show the filename
   **And** the status bar should show "App: [filename]"

### UI Components Required
```jsx
// Top Toolbar Component
<div className="bg-white border-b border-gray-200 px-4 py-3 flex items-center justify-between">
  <div className="flex items-center space-x-4">
    <h1 className="text-xl font-semibold text-gray-800">AI-QA Agent</h1>
    <div className="flex items-center space-x-2">
      <Smartphone className="w-4 h-4 text-gray-500" />
      <select className="border border-gray-300 rounded px-2 py-1 text-sm">
        {/* Device options */}
      </select>
    </div>
    <div className="flex items-center space-x-2">
      <Upload className="w-4 h-4 text-gray-500" />
      <input type="file" accept=".apk" className="hidden" />
      <label className="cursor-pointer border border-gray-300 rounded px-2 py-1 text-sm bg-gray-50 hover:bg-gray-100">
        Upload APK
      </label>
    </div>
  </div>
  <div className="flex items-center space-x-2">
    <label className="flex items-center space-x-2 text-sm">
      <input type="checkbox" className="rounded" />
      <span>Verbose Logging</span>
    </label>
    <button className="p-2 text-gray-500 hover:text-gray-700">
      <Settings className="w-4 h-4" />
    </button>
  </div>
</div>
```

### Testing Instructions
1. Open web interface in browser
2. Verify all UI elements render correctly
3. Test device dropdown selection
4. Test APK file upload (mock file)
5. Toggle verbose logging checkbox
6. Verify status bar updates

### Definition of Done
- [ ] UI renders with specified layout (60/40 split)
- [ ] All toolbar controls are functional
- [ ] Device selection updates status bar
- [ ] File upload shows selected filename
- [ ] Responsive design works on desktop browsers
- [ ] No console errors in browser dev tools

---

## Story 2: Command Input & Plan Generation Interface
**Priority**: Must Have | **Sprint**: 1 | **Points**: 5

### Story Description
As a **manual tester**, I want to **input natural language test commands and see generated execution plans** so that I can **review and understand what actions will be performed before execution**.

### Acceptance Criteria
1. **Given** I am on the main interface
   **When** I look at the right panel
   **Then** I should see:
   - Command input section at the top with textarea
   - "Quick Commands" section with 4 predefined commands
   - Plan preview section (appears after command input)

2. **Given** I want to enter a test command
   **When** I click in the textarea
   **Then** I should see placeholder text: "Enter natural language test command..."
   **And** the textarea should accept multi-line input (3 rows)

3. **Given** I see the quick commands section
   **When** I view the available options
   **Then** I should see these clickable commands:
   - "Search for McDonald's and open its page"
   - "Login with valid credentials" 
   - "Add item to cart and checkout"
   - "Navigate to profile settings"

4. **Given** I click a quick command
   **When** I select "Search for McDonald's and open its page"
   **Then** the textarea should populate with that command
   **And** a plan preview should appear below

5. **Given** I have entered a command
   **When** the plan preview is generated
   **Then** I should see:
   - "Generated Plan" heading with confidence score (e.g., "Confidence: 92%")
   - List of 4 planned steps with action types and descriptions
   - Each step showing: action name in blue monospace font + description in gray

### UI Components Required
```jsx
// Command Input Section
<div className="p-4 border-b border-gray-200">
  <div className="space-y-3">
    <label className="block text-sm font-medium text-gray-700">Test Command</label>
    <textarea
      placeholder="Enter natural language test command..."
      className="w-full p-3 border border-gray-300 rounded-lg resize-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
      rows={3}
    />
    
    {/* Quick Commands */}
    <div className="space-y-2">
      <span className="text-xs text-gray-500">Quick Commands:</span>
      <div className="grid gap-1">
        {quickCommands.map((cmd, idx) => (
          <button
            key={idx}
            className="text-left text-xs text-blue-600 hover:text-blue-800 hover:bg-blue-50 p-1 rounded"
          >
            {cmd}
          </button>
        ))}
      </div>
    </div>
  </div>
</div>

// Plan Preview Section
<div className="p-4 border-b border-gray-200 bg-gray-50">
  <div className="space-y-3">
    <div className="flex items-center justify-between">
      <span className="text-sm font-medium text-gray-700">Generated Plan</span>
      <span className="text-xs text-gray-500">Confidence: 92%</span>
    </div>
    
    <div className="space-y-1">
      {generatedPlan.steps.map((step, idx) => (
        <div key={idx} className="text-xs p-2 bg-white rounded border">
          <span className="font-mono text-blue-600">{step.action}</span>
          <span className="ml-2 text-gray-600">{step.description}</span>
        </div>
      ))}
    </div>
  </div>
</div>
```

### Mock Data for Testing
```javascript
const quickCommands = [
  "Search for McDonald's and open its page",
  "Login with valid credentials",
  "Add item to cart and checkout",
  "Navigate to profile settings"
];

const generatedPlan = {
  app: "in.swiggy.android",
  confidence: 0.92,
  steps: [
    { action: "launch_app", description: "Launch the Swiggy app" },
    { action: "click", description: "Click on search bar" },
    { action: "type", description: "Type search query 'McDonald's'" },
    { action: "click", description: "Select McDonald's from results" }
  ]
};
```

### Testing Instructions
1. Verify textarea renders with correct placeholder
2. Type various commands and verify text input works
3. Click each quick command and verify textarea populates
4. Verify plan preview appears with mock data
5. Check confidence score displays correctly
6. Verify each step shows action type and description

### Definition of Done
- [ ] Command input textarea functional with 3-row height
- [ ] All 4 quick commands clickable and populate textarea
- [ ] Plan preview renders when command is present
- [ ] Confidence score displays as percentage
- [ ] Plan steps show proper formatting (blue action, gray description)
- [ ] Layout matches specified styling

---

## Story 3: Emulator Display & Device Simulation
**Priority**: Must Have | **Sprint**: 2 | **Points**: 8

### Story Description
As a **manual tester**, I want to **see a realistic Android device emulator with app interface** so that I can **visually track test execution and understand the current app state**.

### Acceptance Criteria
1. **Given** I am viewing the main interface
   **When** I look at the left panel (emulator area)
   **Then** I should see:
   - Black background (320x640px centered device frame)
   - Realistic device bezels and physical button representations
   - Android status bar with time "9:41" and signal indicators

2. **Given** the device is displaying an app
   **When** I view the simulated Swiggy app
   **Then** I should see:
   - Blue gradient background (from-blue-500 to-blue-600)
   - "Swiggy" app title in white text
   - Location selector showing "üìç Bengaluru, Karnataka"
   - Search bar with search icon and placeholder
   - Special offers banner placeholder

3. **Given** a test is executing
   **When** I see step "Type 'McDonald's'" is running
   **Then** the search bar input should show "McDonald's" text
   **And** a spinning loading indicator should appear centered on screen

4. **Given** different execution states
   **When** the execution status changes
   **Then** the device display should update:
   - Idle: Clean app interface
   - Running: Loading spinner overlay
   - Input step: Show typed text in relevant fields

### UI Components Required
```jsx
// Emulator Display Component
<div className="w-3/5 bg-black p-4 flex items-center justify-center">
  <div className="relative bg-gray-800 rounded-lg p-6" style={{width: '320px', height: '640px'}}>
    <div className="w-full h-full bg-white rounded flex items-center justify-center relative overflow-hidden">
      {/* Simulated Android Screen */}
      <div className="w-full h-full bg-gradient-to-b from-blue-500 to-blue-600">
        {/* Status Bar */}
        <div className="h-6 bg-black bg-opacity-20 flex items-center justify-between px-2">
          <span className="text-white text-xs">9:41</span>
          <div className="flex space-x-1">
            <div className="w-4 h-2 bg-white rounded-sm opacity-80"></div>
            <div className="w-4 h-2 bg-white rounded-sm opacity-60"></div>
            <div className="w-4 h-2 bg-white rounded-sm opacity-40"></div>
          </div>
        </div>
        
        {/* App Content */}
        <div className="p-4 space-y-4">
          <div className="text-white text-center">
            <h2 className="text-lg font-semibold">Swiggy</h2>
          </div>
          
          {/* Location */}
          <div className="bg-white bg-opacity-20 rounded p-2">
            <span className="text-white text-sm">üìç Bengaluru, Karnataka</span>
          </div>
          
          {/* Search Bar */}
          <div className="bg-white rounded-lg p-3 shadow-lg">
            <div className="flex items-center space-x-2">
              <Search className="w-4 h-4 text-gray-400" />
              <input 
                type="text" 
                placeholder="Search for restaurants"
                className="flex-1 outline-none text-sm"
                value={executionStatus === 'running' && currentStep >= 2 ? "McDonald's" : ""}
                readOnly
              />
            </div>
          </div>
          
          {/* Banner */}
          <div className="bg-white bg-opacity-20 rounded-lg h-20 flex items-center justify-center">
            <span className="text-white text-sm">Special Offers</span>
          </div>
        </div>
        
        {/* Execution Indicator */}
        {executionStatus === 'running' && (
          <div className="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2">
            <div className="w-8 h-8 border-4 border-yellow-400 border-t-transparent rounded-full animate-spin"></div>
          </div>
        )}
      </div>
    </div>
    
    {/* Device Frame */}
    <div className="absolute inset-0 border-8 border-gray-700 rounded-2xl pointer-events-none"></div>
    <div className="absolute top-2 left-1/2 transform -translate-x-1/2 w-12 h-1 bg-gray-600 rounded-full"></div>
    <div className="absolute bottom-2 left-1/2 transform -translate-x-1/2 w-8 h-8 border-2 border-gray-600 rounded-full"></div>
  </div>
</div>
```

### State Management Required
```javascript
const [executionStatus, setExecutionStatus] = useState('idle'); // idle, running, paused, completed, failed
const [currentStep, setCurrentStep] = useState(0);
```

### Testing Instructions
1. Verify device frame renders with correct dimensions (320x640px)
2. Check Android status bar shows time "9:41" and signal bars
3. Verify Swiggy app interface displays correctly
4. Test execution status changes:
   - Set status to 'running' and verify spinner appears
   - Set currentStep >= 2 and verify search text appears
5. Verify device bezels and home button are visible
6. Check responsive centering in left panel

### Definition of Done
- [ ] Device frame renders with realistic bezels and dimensions
- [ ] Android status bar displays correctly
- [ ] Swiggy app interface matches design
- [ ] Loading spinner shows during execution
- [ ] Search text appears when currentStep >= 2
- [ ] Device is centered in left panel (60% width)
- [ ] All visual elements match specified styling

---

## Story 4: Execution Controls & Test Management
**Priority**: Must Have | **Sprint**: 2 | **Points**: 5

### Story Description
As a **manual tester**, I want to **control test execution with start, pause, step, and abort functions** so that I can **manage test runs and debug issues during execution**.

### Acceptance Criteria
1. **Given** I have entered a test command with generated plan
   **When** I look below the plan preview
   **Then** I should see 5 execution control buttons:
   - Green "Start" button with play icon
   - Yellow "Pause" button with pause icon  
   - Blue "Step" button with skip-forward icon
   - Red "Abort" button with square icon
   - Gray "Rerun" button with rotate icon

2. **Given** no command is entered or execution is idle
   **When** I view the control buttons
   **Then** "Start" should be disabled (gray background)
   **And** "Pause", "Step", "Abort" should be disabled
   **And** "Rerun" should be enabled

3. **Given** I click the "Start" button with a valid command
   **When** execution begins
   **Then** the execution status should change to 'running'
   **And** "Start" button should be disabled
   **And** "Pause", "Step", "Abort" buttons should be enabled
   **And** the emulator should show loading spinner

4. **Given** execution is running
   **When** I click "Pause"
   **Then** execution status should change to 'paused'
   **And** "Start" button should be re-enabled (now acts as "Resume")
   **And** loading spinner should disappear

5. **Given** execution is running
   **When** I click "Step"
   **Then** execution should advance one step
   **And** current step counter should increment
   **And** execution should pause automatically

6. **Given** execution is running
   **When** I click "Abort"
   **Then** execution status should change to 'idle'
   **And** all buttons should return to initial state
   **And** current step should reset to 0

### UI Components Required
```jsx
// Execution Controls Component
<div className="flex space-x-2 pt-2">
  <button
    onClick={handleStart}
    disabled={isExecuting || !command}
    className="flex items-center space-x-1 px-3 py-2 bg-green-600 text-white rounded text-sm hover:bg-green-700 disabled:bg-gray-400"
  >
    <Play className="w-3 h-3" />
    <span>Start</span>
  </button>
  
  <button
    disabled={!isExecuting}
    className="flex items-center space-x-1 px-3 py-2 bg-yellow-600 text-white rounded text-sm hover:bg-yellow-700 disabled:bg-gray-400"
  >
    <Pause className="w-3 h-3" />
    <span>Pause</span>
  </button>
  
  <button
    disabled={!isExecuting}
    className="flex items-center space-x-1 px-3 py-2 bg-blue-600 text-white rounded text-sm hover:bg-blue-700 disabled:bg-gray-400"
  >
    <SkipForward className="w-3 h-3" />
    <span>Step</span>
  </button>
  
  <button
    disabled={!isExecuting}
    className="flex items-center space-x-1 px-3 py-2 bg-red-600 text-white rounded text-sm hover:bg-red-700 disabled:bg-gray-400"
  >
    <Square className="w-3 h-3" />
    <span>Abort</span>
  </button>
  
  <button className="flex items-center space-x-1 px-3 py-2 bg-gray-600 text-white rounded text-sm hover:bg-gray-700">
    <RotateCcw className="w-3 h-3" />
    <span>Rerun</span>
  </button>
</div>
```

### State Management & Handlers Required
```javascript
const [isExecuting, setIsExecuting] = useState(false);
const [executionStatus, setExecutionStatus] = useState('idle');
const [currentStep, setCurrentStep] = useState(0);

const handleStart = () => {
  setIsExecuting(true);
  setExecutionStatus('running');
  // Simulate execution progress
  setTimeout(() => {
    setExecutionStatus('completed');
    setIsExecuting(false);
  }, 5000);
};

const handlePause = () => {
  setExecutionStatus('paused');
  setIsExecuting(false);
};

const handleStep = () => {
  setCurrentStep(prev => prev + 1);
  // Execute single step then pause
};

const handleAbort = () => {
  setExecutionStatus('idle');
  setIsExecuting(false);
  setCurrentStep(0);
};
```

### Testing Instructions
1. Start with no command - verify "Start" is disabled
2. Enter a command - verify "Start" becomes enabled
3. Click "Start" - verify state changes and other buttons enable
4. Test each button function:
   - Start: begins execution
   - Pause: stops execution, allows resume
   - Step: advances one step and pauses
   - Abort: stops and resets everything
   - Rerun: restarts from beginning
5. Verify button states match execution status
6. Check emulator spinner appears/disappears correctly

### Definition of Done
- [ ] All 5 control buttons render with correct colors and icons
- [ ] Button enable/disable states work correctly
- [ ] Start button initiates execution and updates state
- [ ] Pause button stops execution and enables resume
- [ ] Step button advances execution by one step
- [ ] Abort button stops and resets execution
- [ ] Rerun button restarts execution from beginning
- [ ] Emulator loading indicator syncs with execution state

---

## Story 5: Execution Log & Step Timeline
**Priority**: Must Have | **Sprint**: 3 | **Points**: 8

### Story Description
As a **manual tester**, I want to **view detailed execution logs with expandable step information** so that I can **track test progress, debug failures, and review execution details**.

### Acceptance Criteria
1. **Given** I am viewing the right panel
   **When** I look at the bottom section
   **Then** I should see 3 tabs:
   - "Execution Log" (active by default)
   - "Inspector" with tree icon
   - "History" with history icon

2. **Given** I am on the Execution Log tab
   **When** execution starts or steps are available
   **Then** I should see a list of execution steps showing:
   - Status icon (green checkmark, red X, blue spinning clock, gray clock)
   - Step description (e.g., "Launch Swiggy app", "Click search bar")
   - Timestamp (e.g., "10:30:45")
   - Duration in parentheses (e.g., "(2.1s)")
   - Camera icon if screenshot available
   - Expand/collapse chevron arrow

3. **Given** I see an execution step
   **When** I click on the step row
   **Then** the step should expand to show:
   - Action type in code format (e.g., `launch_app`)
   - Screenshot view button (if available)
   - "View XML" button for page source
   - Gray background with border separator

4. **Given** I have multiple execution steps
   **When** I view the step list
   **Then** I should see these sample steps:
   - "Launch Swiggy app" - completed, 2.1s duration
   - "Click search bar" - completed, 0.8s duration  
   - "Type 'McDonald's'" - running, 1.2s duration
   - "Select McDonald's from suggestions" - pending, no timestamp

5. **Given** I want to switch between tabs
   **When** I click "Inspector" or "History" tabs
   **Then** the tab should become active (blue border and text)
   **And** the content area should change accordingly

### UI Components Required
```jsx
// Tab Headers
<div className="flex border-b border-gray-200">
  <button 
    onClick={() => setInspectorView('execution')}
    className={`px-4 py-2 text-sm font-medium border-b-2 ${
      inspectorView === 'execution' 
        ? 'border-blue-500 text-blue-600' 
        : 'border-transparent text-gray-500 hover:text-gray-700'
    }`}
  >
    Execution Log
  </button>
  <button 
    onClick={() => setInspectorView('elements')}
    className={`px-4 py-2 text-sm font-medium border-b-2 ${
      inspectorView === 'elements' 
        ? 'border-blue-500 text-blue-600' 
        : 'border-transparent text-gray-500 hover:text-gray-700'
    }`}
  >
    <div className="flex items-center space-x-1">
      <TreePine className="w-4 h-4" />
      <span>Inspector</span>
    </div>
  </button>
  <button 
    onClick={() => setInspectorView('history')}
    className={`px-4 py-2 text-sm font-medium border-b-2 ${
      inspectorView === 'history' 
        ? 'border-blue-500 text-blue-600' 
        : 'border-transparent text-gray-500 hover:text-gray-700'
    }`}
  >
    <div className="flex items-center space-x-1">
      <History className="w-4 h-4" />
      <span>History</span>
    </div>
  </button>
</div>

// Execution Step Component  
<div className="border border-gray-200 rounded-lg">
  <div 
    className="p-3 cursor-pointer hover:bg-gray-50 flex items-center justify-between"
    onClick={() => toggleStepExpansion(step.id)}
  >
    <div className="flex items-center space-x-3">
      {getStatusIcon(step.status)}
      <div>
        <div className="text-sm font-medium">{step.description}</div>
        <div className="text-xs text-gray-500 flex space-x-2">
          <span>{step.timestamp}</span>
          {step.duration && <span>({step.duration})</span>}
        </div>
      </div>
    </div>
    <div className="flex items-center space-x-2">
      {step.screenshot && <Camera className="w-4 h-4 text-gray-400" />}
      {expandedSteps.has(step.id) ? 
        <ChevronDown className="w-4 h-4 text-gray-400" /> :
        <ChevronRight className="w-4 h-4 text-gray-400" />
      }
    </div>
  </div>
  
  {expandedSteps.has(step.id) && (
    <div className="px-3 pb-3 border-t border-gray-100 bg-gray-50">
      <div className="pt-3 space-y-2">
        <div className="text-xs">
          <strong>Action:</strong> <code className="bg-gray-200 px-1 rounded">{step.action}</code>
        </div>
        {step.screenshot && (
          <div className="text-xs">
            <strong>Screenshot:</strong> 
            <button className="ml-2 text-blue-600 hover:text-blue-800">View</button>
          </div>
        )}
        <div className="text-xs">
          <strong>Page Source:</strong> 
          <button className="ml-2 text-blue-600 hover:text-blue-800">View XML</button>
        </div>
      </div>
    </div>
  )}
</div>
```

### Mock Data Required
```javascript
const executionSteps = [
  {
    id: 1,
    action: 'launch_app',
    description: 'Launch Swiggy app',
    status: 'completed',
    timestamp: '10:30:45',
    screenshot: true,
    duration: '2.1s'
  },
  {
    id: 2,
    action: 'click',
    description: 'Click search bar',
    status: 'completed',
    timestamp: '10:30:47',
    screenshot: true,
    duration: '0.8s'
  },
  {
    id: 3,
    action: 'type',
    description: 'Type "McDonald\'s"',
    status: 'running',
    timestamp: '10:30:48',
    screenshot: false,
    duration: '1.2s'
  },
  {
    id: 4,
    action: 'click',
    description: 'Select McDonald\'s from suggestions',
    status: 'pending',
    timestamp: '',
    screenshot: false,
    duration: ''
  }
];

const getStatusIcon = (status) => {
  switch (status) {
    case 'completed':
      return <CheckCircle className="w-4 h-4 text-green-500" />;
    case 'failed':
      return <XCircle className="w-4 h-4 text-red-500" />;
    case 'running':
      return <Clock className="w-4 h-4 text-blue-500 animate-spin" />;
    default:
      return <Clock className="w-4 h-4 text-gray-400" />;
  }
};
```

### Testing Instructions
1. Verify 3 tabs render with correct icons and labels
2. Check "Execution Log" tab is active by default
3. Verify execution steps display with all required information
4. Test step expansion:
   - Click step to expand
   - Verify expanded content shows
   - Click again to collapse
5. Test status icons for different states
6. Verify camera icon appears only when screenshot available
7. Test tab switching functionality

### Definition of Done
- [ ] 3 tabs render with correct styling and icons
- [ ] Execution Log tab is active by default
- [ ] All execution steps display with proper formatting
- [ ] Step expansion/collapse works correctly
- [ ] Status icons show correct colors and animations
- [ ] Screenshots and page source buttons appear in expanded view
- [ ] Tab switching updates active state and content
- [ ] Scrollable content area for long execution logs

**Priority**: Must Have | **Sprint**: 4 | **Points**: 13

### Story Description
As a **manual tester**, I want the **system to use AI/LLM to automatically generate test plans from my natural language commands** so that I can **get intelligent, context-aware automation without writing scripts**.

### Acceptance Criteria
1. **Given** I enter a natural language command
   **When** I type "Search for McDonald's and open its page"
   **Then** the system should call an LLM API with prompt containing:
   - User command
   - Current UI element context
   - App package name (e.g., "in.swiggy.android")
   - Device information

2. **Given** the LLM processes my command
   **When** the API returns a response
   **Then** I should see:
   - Generated plan with realistic confidence score (80-95%)
   - Structured steps with action types and descriptions
   - Plan updates in real-time (not just static mock data)

3. **Given** different types of commands
   **When** I test various scenarios
   **Then** the LLM should generate appropriate plans for:
   - "Login with valid credentials" ‚Üí Authentication flow
   - "Add item to cart and checkout" ‚Üí E-commerce flow  
   - "Navigate to profile settings" ‚Üí Navigation flow
   - "Search for cheap pizza nearby" ‚Üí Search with filters

4. **Given** the system needs UI context
   **When** generating plans
   **Then** the LLM should receive:
   - Current page source (trimmed for token limits)
   - Available UI elements with IDs and properties
   - Screenshot description or analysis
   - Previous step history (if any)

5. **Given** an LLM API failure or timeout
   **When** the service is unavailable
   **Then** I should see:
   - Error message: "AI service temporarily unavailable"
   - Fallback to predefined plan templates
   - Option to retry plan generation

### Technical Implementation Required

#### LLM Service Integration
```javascript
// LLM API Service
class LLMService {
  async generatePlan(command, context) {
    const prompt = this.buildPrompt(command, context);
    
    try {
      const response = await fetch('/api/llm/generate-plan', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          prompt,
          max_tokens: 1000,
          temperature: 0.3,
          model: 'gpt-4'
        })
      });
      
      const result = await response.json();
      return this.validatePlan(result.plan);
      
    } catch (error) {
      console.error('LLM API Error:', error);
      return this.getFallbackPlan(command);
    }
  }
  
  buildPrompt(command, context) {
    return `
System: You are a mobile automation expert. Generate JSON test plans from natural language commands.

Current App: ${context.appPackage}
Available Elements: ${JSON.stringify(context.elements, null, 2)}
User Command: "${command}"

Generate a JSON plan with this schema:
{
  "confidence": 0.85,
  "app": "package.name",
  "steps": [
    {"action": "launch_app", "description": "Launch the app"},
    {"action": "click", "by": "id", "selector": "element_id", "description": "Click element"},
    {"action": "type", "text": "input_text", "description": "Type text"}
  ]
}

Supported actions: launch_app, click, type, swipe, wait_for_element, take_screenshot
`;
  }
}
```

#### Plan Validation Schema
```javascript
const PlanSchema = {
  type: 'object',
  required: ['confidence', 'app', 'steps'],
  properties: {
    confidence: { type: 'number', minimum: 0, maximum: 1 },
    app: { type: 'string' },
    steps: {
      type: 'array',
      items: {
        type: 'object',
        required: ['action', 'description'],
        properties: {
          action: { 
            type: 'string',
            enum: ['launch_app', 'click', 'type', 'swipe', 'wait_for_element', 'take_screenshot']
          },
          by: { type: 'string', enum: ['id', 'xpath', 'class', 'text'] },
          selector: { type: 'string' },
          text: { type: 'string' },
          description: { type: 'string' }
        }
      }
    }
  }
};

function validatePlan(plan) {
  const ajv = new Ajv();
  const validate = ajv.compile(PlanSchema);
  
  if (!validate(plan)) {
    throw new Error(`Invalid plan: ${validate.errors}`);
  }
  return plan;
}
```

#### Frontend Integration
```javascript
const CommandInput = () => {
  const [command, setCommand] = useState('');
  const [plan, setPlan] = useState(null);
  const [isGenerating, setIsGenerating] = useState(false);
  const [error, setError] = useState(null);
  
  const generatePlan = async (command) => {
    setIsGenerating(true);
    setError(null);
    
    try {
      const context = {
        appPackage: 'in.swiggy.android',
        elements: uiElements,
        deviceInfo: selectedDevice
      };
      
      const llmService = new LLMService();
      const generatedPlan = await llmService.generatePlan(command, context);
      
      setPlan(generatedPlan);
    } catch (err) {
      setError(err.message);
      setPlan(getFallbackPlan(command));
    } finally {
      setIsGenerating(false);
    }
  };
  
  useEffect(() => {
    if (command.length > 10) {
      const debounceTimer = setTimeout(() => {
        generatePlan(command);
      }, 1000);
      
      return () => clearTimeout(debounceTimer);
    }
  }, [command]);
  
  return (
    <div className="space-y-3">
      <textarea
        value={command}
        onChange={(e) => setCommand(e.target.value)}
        placeholder="Enter natural language test command..."
        className="w-full p-3 border border-gray-300 rounded-lg"
      />
      
      {isGenerating && (
        <div className="flex items-center space-x-2 text-blue-600">
          <Clock className="w-4 h-4 animate-spin" />
          <span className="text-sm">AI is generating your test plan...</span>
        </div>
      )}
      
      {error && (
        <div className="flex items-center space-x-2 text-red-600 bg-red-50 p-2 rounded">
          <AlertCircle className="w-4 h-4" />
          <span className="text-sm">{error}</span>
          <button onClick={() => generatePlan(command)} className="text-xs underline">
            Retry
          </button>
        </div>
      )}
      
      {plan && <PlanPreview plan={plan} />}
    </div>
  );
};
```

### Testing Instructions
1. **Setup LLM API**: Configure OpenAI/Claude API keys and endpoints
2. **Test Command Processing**: 
   - Enter "Search for McDonald's" ‚Üí Verify LLM API call
   - Check generated plan structure matches schema
   - Verify confidence score is realistic (0.8-0.95)
3. **Test Different Command Types**:
   - Authentication: "Login with admin credentials"
   - Navigation: "Go to settings page" 
   - Search: "Find pizza restaurants nearby"
   - E-commerce: "Add item to cart and checkout"
4. **Test Error Handling**:
   - Disconnect internet ‚Üí Verify fallback plan
   - Invalid API key ‚Üí Show appropriate error
   - Malformed LLM response ‚Üí Validate and reject
5. **Performance Testing**:
   - Verify debounced API calls (1 second delay)
   - Check response time < 5 seconds
   - Test concurrent plan generation

### Definition of Done
- [x] LLM API integration working with OpenAI/Claude
- [x] Plan generation triggered by command input (debounced)
- [x] Generated plans follow required JSON schema
- [x] Plan validation rejects malformed responses
- [x] Error handling for API failures with fallback plans
- [x] Loading states during plan generation
- [x] Confidence scores reflect plan quality
- [x] Context-aware plans based on current UI state

### ‚úÖ **Story 6 Status: COMPLETED**

**Implementation Summary:**
- Built enhanced AI-like plan generation system with intelligent command analysis
- Implemented multiple plan templates for different use cases (search, order, login, fallback)
- Added comprehensive schema validation with structured interfaces
- Created retry logic with up to 3 attempts and degraded confidence scoring
- Implemented deterministic fallback plans for failure scenarios
- Added loading states with attempt counters and progress indication
- Created confidence scoring with color-coded visual feedback
- Added plan metadata including complexity, duration estimates, and auth requirements
- Integrated command analysis to select appropriate plan templates
- Built foundation for future real LLM integration

**Acceptance Criteria Verification:**
‚úÖ AI-like plan generation responds intelligently to different command types  
‚úÖ Plan generation triggered by debounced command input with loading indicators  
‚úÖ All generated plans follow strict JSON schema with validation  
‚úÖ Schema validation rejects malformed responses and triggers retries  
‚úÖ Comprehensive error handling with fallback plans after 3 failed attempts  
‚úÖ Loading states show generation progress with attempt counters  
‚úÖ Confidence scores reflect plan quality with color-coded visual feedback  
‚úÖ Plans are context-aware based on command analysis and previous attempts  

---

## üîß **Story 7: AI-Powered Execution Replanning**
**Priority**: Must Have | **Sprint**: 5 | **Points**: 10

### Story Description
As a **manual tester**, I want the **AI to automatically replan test steps when execution fails** so that my **tests can self-heal and handle dynamic UI changes without manual intervention**.

### Acceptance Criteria
1. **Given** a test step fails during execution
   **When** the system detects the failure (element not found, timeout, etc.)
   **Then** the AI should automatically:
   - Capture current UI state and screenshot
   - Analyze the failure reason
   - Generate a new plan to achieve the original goal
   - Continue execution with updated steps

2. **Given** a common failure scenario
   **When** executing "Click search bar" but permission popup appears
   **Then** the AI should:
   - Detect the popup is blocking the action
   - Generate new steps: ["Handle permission", "Then click search bar"]
   - Update the execution log with replanning information
   - Show confidence score for the new plan

3. **Given** multiple replanning attempts
   **When** the AI tries to recover from failures
   **Then** the system should:
   - Limit replanning attempts to 3 maximum
   - Show decreasing confidence with each retry
   - Escalate to human intervention after max attempts
   - Log all replanning decisions for debugging

4. **Given** successful replanning
   **When** the AI generates a recovery plan
   **Then** I should see:
   - "Replanning" notification in execution log
   - Updated step list with new actions
   - Reason for replanning (e.g., "Permission dialog detected")
   - Continued execution without stopping

5. **Given** replanning fails completely
   **When** the AI cannot find a solution after 3 attempts
   **Then** I should see:
   - Execution paused with "Human intervention required" status
   - Summary of attempted solutions
   - Option to manually provide guidance
   - Option to abort the test

### Technical Implementation Required

#### Replanning Service
```javascript
class ReplanningService {
  constructor(llmService, maxAttempts = 3) {
    this.llmService = llmService;
    this.maxAttempts = maxAttempts;
  }
  
  async handleFailure(originalGoal, failedStep, context) {
    const { currentUI, error, stepHistory, attemptCount = 1 } = context;
    
    if (attemptCount > this.maxAttempts) {
      return {
        success: false,
        reason: 'Max replanning attempts exceeded',
        requiresHuman: true
      };
    }
    
    try {
      const replanPrompt = this.buildReplanPrompt({
        originalGoal,
        failedStep,
        currentUI,
        error,
        stepHistory,
        attemptCount
      });
      
      const newPlan = await this.llmService.replan(replanPrompt);
      
      return {
        success: true,
        newPlan,
        reason: newPlan.reasoning,
        confidence: newPlan.confidence * (1 - (attemptCount - 1) * 0.2), // Decrease confidence with retries
        attemptCount: attemptCount + 1
      };
      
    } catch (error) {
      console.error('Replanning failed:', error);
      return await this.handleFailure(originalGoal, failedStep, {
        ...context,
        attemptCount: attemptCount + 1
      });
    }
  }
  
  buildReplanPrompt({ originalGoal, failedStep, currentUI, error, stepHistory, attemptCount }) {
    return `
System: You are a mobile test automation expert. A test step failed and needs replanning.

Original Goal: "${originalGoal}"
Failed Step: ${JSON.stringify(failedStep)}
Error: "${error}"
Current UI State: ${JSON.stringify(currentUI.elements.slice(0, 10))} // Trimmed for tokens
Previous Steps: ${JSON.stringify(stepHistory)}
Attempt Number: ${attemptCount}

Analyze the failure and provide a corrected plan:
{
  "reasoning": "Why the original step failed and how to fix it",
  "confidence": 0.85,
  "corrected_steps": [
    {"action": "...", "description": "Handle the blocking issue"},
    {"action": "...", "description": "Continue with original intent"}
  ]
}

Common failure patterns to handle:
- Permission dialogs: Handle popup then continue
- Loading states: Wait for elements to appear
- UI changes: Find alternative selectors
- Network issues: Retry with backoff
`;
  }
}
```

#### Execution Engine with Replanning
```javascript
class ExecutionEngine {
  constructor(replanningService) {
    this.replanningService = replanningService;
    this.executionState = {
      currentStep: 0,
      originalGoal: '',
      plan: null,
      stepHistory: [],
      replanningCount: 0
    };
  }
  
  async executeStep(step, stepIndex) {
    try {
      // Attempt to execute the step
      const result = await this.performAction(step);
      
      // Validate the result
      const currentUI = await this.captureUIState();
      if (!this.validateStepSuccess(step, result, currentUI)) {
        throw new Error(`Step validation failed: Expected result not achieved`);
      }
      
      // Step succeeded
      this.executionState.stepHistory.push({
        ...step,
        status: 'completed',
        timestamp: new Date().toISOString(),
        result
      });
      
      return { success: true, result };
      
    } catch (error) {
      console.log(`Step failed: ${error.message}. Attempting replanning...`);
      
      // Capture failure context
      const failureContext = {
        currentUI: await this.captureUIState(),
        error: error.message,
        stepHistory: this.executionState.stepHistory,
        attemptCount: this.executionState.replanningCount + 1
      };
      
      // Attempt replanning
      const replanResult = await this.replanningService.handleFailure(
        this.executionState.originalGoal,
        step,
        failureContext
      );
      
      if (!replanResult.success) {
        return {
          success: false,
          error: error.message,
          requiresHuman: replanResult.requiresHuman,
          replanningAttempts: this.executionState.replanningCount
        };
      }
      
      // Apply new plan and continue
      this.applyReplan(replanResult, stepIndex);
      return { success: true, replanned: true, newPlan: replanResult.newPlan };
    }
  }
  
  applyReplan(replanResult, fromStepIndex) {
    // Update execution log
    this.addReplanningLogEntry(replanResult);
    
    // Insert new steps into current plan
    const newSteps = replanResult.newPlan.corrected_steps;
    this.executionState.plan.steps.splice(fromStepIndex, 1, ...newSteps);
    
    // Update replanning count
    this.executionState.replanningCount = replanResult.attemptCount;
  }
  
  addReplanningLogEntry(replanResult) {
    const logEntry = {
      id: Date.now(),
      type: 'replanning',
      description: `AI Replanning: ${replanResult.reason}`,
      status: 'completed',
      timestamp: new Date().toLocaleTimeString(),
      confidence: replanResult.confidence,
      screenshot: false,
      expandedInfo: {
        reason: replanResult.reason,
        newSteps: replanResult.newPlan.corrected_steps,
        attemptNumber: replanResult.attemptCount
      }
    };
    
    // Add to execution log
    this.emit('replanningEvent', logEntry);
  }
}
```

#### Frontend Replanning Integration
```javascript
const ExecutionLog = () => {
  const [executionSteps, setExecutionSteps] = useState([]);
  
  useEffect(() => {
    // Listen for replanning events
    executionEngine.on('replanningEvent', (replanEntry) => {
      setExecutionSteps(prev => [...prev, replanEntry]);
    });
  }, []);
  
  const ReplanningStep = ({ step }) => (
    <div className="border border-orange-200 rounded-lg bg-orange-50">
      <div className="p-3 flex items-center space-x-3">
        <AlertCircle className="w-4 h-4 text-orange-500" />
        <div>
          <div className="text-sm font-medium text-orange-800">
            {step.description}
          </div>
          <div className="text-xs text-orange-600">
            Attempt {step.expandedInfo.attemptNumber} ‚Ä¢ Confidence: {(step.confidence * 100).toFixed(0)}%
          </div>
        </div>
      </div>
      
      {expandedSteps.has(step.id) && (
        <div className="px-3 pb-3 border-t border-orange-200 bg-orange-25">
          <div className="pt-3 space-y-2">
            <div className="text-xs">
              <strong>Reason:</strong> {step.expandedInfo.reason}
            </div>
            <div className="text-xs">
              <strong>New Steps:</strong>
              <ul className="mt-1 ml-4 list-disc">
                {step.expandedInfo.newSteps.map((newStep, idx) => (
                  <li key={idx}>{newStep.description}</li>
                ))}
              </ul>
            </div>
          </div>
        </div>
      )}
    </div>
  );
  
  // ... render regular steps and replanning steps
};
```

### Testing Instructions
1. **Setup Failure Scenarios**:
   - Mock element not found errors
   - Simulate permission popup appearing
   - Test network timeout scenarios
2. **Test Replanning Triggers**:
   - Start execution that will fail
   - Verify replanning service is called
   - Check new plan generation
3. **Test Replanning Limits**:
   - Force 3+ failures
   - Verify escalation to human intervention
   - Check max attempt enforcement
4. **Test UI Updates**:
   - Verify replanning log entries appear
   - Check confidence score decreases with attempts
   - Test expandable replanning details

### Definition of Done
- [ ] Replanning service integrates with LLM API
- [ ] Failed step detection triggers automatic replanning
- [ ] Maximum 3 replanning attempts before human escalation
- [ ] Replanning entries appear in execution log with orange styling
- [ ] Confidence scores decrease with each replanning attempt
- [ ] UI shows reasoning and new steps in expanded replanning entries
- [ ] Human intervention prompt appears after max attempts
- [ ] Execution continues seamlessly after successful replanning

---

## üß† **Story 8: AI Context Collection & UI Analysis**
**Priority**: Must Have | **Sprint**: 4 | **Points**: 8

### Story Description
As a **system**, I want to **intelligently collect and analyze UI context using AI** so that the **LLM can make informed decisions about element selection and test planning**.

### Acceptance Criteria
1. **Given** the system needs to capture UI context
   **When** preparing data for LLM analysis
   **Then** the system should collect:
   - Complete page source (XML) with element hierarchy
   - Element accessibility properties (content-desc, text, resource-id)
   - Element bounds and visibility status
   - Screenshot analysis with text extraction (OCR)
   - App package name and current activity

2. **Given** the UI context is too large for LLM token limits
   **When** processing the element tree
   **Then** the system should:
   - Prioritize interactive elements (clickable, focusable)
   - Remove decorative elements and containers
   - Trim element tree to ~10-15 most relevant elements
   - Preserve critical navigation and input elements

3. **Given** the AI needs to select elements intelligently
   **When** generating test steps
   **Then** the system should provide:
   - Multiple selector strategies per element (id, xpath, text, accessibility)
   - Element confidence scores based on uniqueness and stability
   - Fallback selectors when primary selection fails
   - Context about element relationships (parent, siblings)

4. **Given** visual information is needed
   **When** the AI analyzes screenshots
   **Then** the system should:
   - Extract visible text using OCR (Tesseract.js or similar)
   - Identify UI patterns (forms, lists, navigation bars)
   - Detect popups, modals, and overlay elements
   - Provide textual description of visual layout

### Technical Implementation Required

#### UI Context Collection Service
```javascript
class UIContextService {
  async captureContext(driver) {
    const [pageSource, screenshot, deviceInfo] = await Promise.all([
      driver.getPageSource(),
      driver.takeScreenshot(),
      this.getDeviceInfo(driver)
    ]);
    
    const elements = await this.parseElements(pageSource);
    const visualAnalysis = await this.analyzeScreenshot(screenshot);
    
    return {
      elements: this.prioritizeElements(elements),
      visualContext: visualAnalysis,
      deviceInfo,
      timestamp: new Date().toISOString()
    };
  }
  
  parseElements(pageSource) {
    const parser = new DOMParser();
    const doc = parser.parseFromString(pageSource, 'text/xml');
    
    const elements = [];
    const traverseNode = (node, depth = 0) => {
      if (node.nodeType === Node.ELEMENT_NODE) {
        const element = {
          tag: node.tagName,
          resourceId: node.getAttribute('resource-id'),
          text: node.getAttribute('text'),
          contentDesc: node.getAttribute('content-desc'),
          className: node.getAttribute('class'),
          bounds: this.parseBounds(node.getAttribute('bounds')),
          clickable: node.getAttribute('clickable') === 'true',
          focusable: node.getAttribute('focusable') === 'true',
          enabled: node.getAttribute('enabled') === 'true',
          depth
        };
        
        // Generate multiple selector strategies
        element.selectors = this.generateSelectors(element);
        element.uniquenessScore = this.calculateUniqueness(element, elements);
        
        elements.push(element);
      }
      
      // Recursively traverse child nodes
      Array.from(node.childNodes).forEach(child => 
        traverseNode(child, depth + 1)
      );
    };
    
    traverseNode(doc.documentElement);
    return elements;
  }
  
  prioritizeElements(elements) {
    // Score elements by importance for test automation
    return elements
      .map(el => ({
        ...el,
        priority: this.calculatePriority(el)
      }))
      .sort((a, b) => b.priority - a.priority)
      .slice(0, 15); // Limit to top 15 elements for LLM context
  }
  
  calculatePriority(element) {
    let score = 0;
    
    // Interactive elements get high priority
    if (element.clickable) score += 10;
    if (element.focusable) score += 8;
    
    // Elements with text content
    if (element.text && element.text.trim()) score += 5;
    if (element.contentDesc) score += 3;
    
    // Input elements are important
    if (element.className.includes('EditText')) score += 15;
    if (element.className.includes('Button')) score += 12;
    
    // Elements with unique identifiers
    if (element.resourceId) score += 7;
    
    // Reduce score for deep nesting (decorative elements)
    score -= element.depth * 0.5;
    
    return score;
  }
  
  generateSelectors(element) {
    const selectors = [];
    
    // Resource ID selector (most stable)
    if (element.resourceId) {
      selectors.push({
        type: 'id',
        value: element.resourceId.split('/').pop(),
        priority: 1
      });
    }
    
    // Text-based selectors
    if (element.text) {
      selectors.push({
        type: 'text',
        value: element.text,
        priority: 2
      });
    }
    
    // Content description selector
    if (element.contentDesc) {
      selectors.push({
        type: 'accessibility',
        value: element.contentDesc,
        priority: 3
      });
    }
    
    // XPath selector (fallback)
    selectors.push({
      type: 'xpath',
      value: this.generateXPath(element),
      priority: 4
    });
    
    return selectors.sort((a, b) => a.priority - b.priority);
  }
  
  async analyzeScreenshot(screenshot) {
    // Use OCR to extract text from screenshot
    const ocrResult = await Tesseract.recognize(screenshot, 'eng');
    
    // Basic visual pattern detection
    const patterns = this.detectUIPatterns(ocrResult);
    
    return {
      extractedText: ocrResult.data.text,
      textBlocks: ocrResult.data.blocks,
      detectedPatterns: patterns,
      description: this.generateVisualDescription(ocrResult, patterns)
    };
  }
  
  generateVisualDescription(ocrResult, patterns) {
    const description = [];
    
    if (patterns.hasSearchBar) description.push("Search interface visible");
    if (patterns.hasLoginForm) description.push("Login form detected");
    if (patterns.hasList) description.push("List or menu items present");
    if (patterns.hasPopup) description.push("Modal or popup overlay detected");
    
    const textCount = ocrResult.data.words.length;
    description.push(`${textCount} text elements visible`);
    
    return description.join(', ');
  }
}
```

#### AI-Enhanced Element Selection
```javascript
class SmartElementSelector {
  constructor(llmService) {
    this.llmService = llmService;
  }
  
  async selectBestElement(intent, availableElements, context) {
    const prompt = `
Analyze these UI elements and select the best one for: "${intent}"

Available elements:
${JSON.stringify(availableElements.slice(0, 10), null, 2)}

Visual context: ${context.visualContext.description}

Return the element index and reasoning:
{
  "selectedIndex": 2,
  "reasoning": "Element has clear 'Search' text and is clickable",
  "confidence": 0.95,
  "fallbackOptions": [0, 4]
}`;

    const response = await this.llmService.analyze(prompt);
    return this.validateSelection(response, availableElements);
  }
  
  async adaptToFailure(originalElement, failureReason, currentElements) {
    const prompt = `
Original element selection failed: ${failureReason}
Original element: ${JSON.stringify(originalElement)}
Current elements: ${JSON.stringify(currentElements.slice(0, 8), null, 2)}

Find alternative element or approach:
{
  "strategy": "alternative_element|wait|different_approach",
  "newElement": {...},
  "reasoning": "Why this should work better"
}`;

    return await this.llmService.analyze(prompt);
  }
}
```

### Testing Instructions
1. **Test UI Context Capture**:
   - Verify page source parsing extracts all elements
   - Check element prioritization (interactive elements first)
   - Validate selector generation for different element types
2. **Test OCR Integration**:
   - Test screenshot text extraction
   - Verify visual pattern detection
   - Check description generation accuracy
3. **Test Smart Element Selection**:
   - Test AI element selection for various intents
   - Verify fallback selector usage
   - Test adaptation after selection failures
4. **Test Context Size Management**:
   - Verify element list is trimmed to ~15 items
   - Check that critical elements are preserved
   - Test with complex UI hierarchies

### Definition of Done
- [ ] UI context collection captures elements, screenshots, and metadata
- [ ] Element prioritization focuses on interactive and important elements  
- [ ] Multiple selector strategies generated per element (id, text, xpath, accessibility)
- [ ] OCR integration extracts text from screenshots
- [ ] Visual pattern detection identifies common UI components
- [ ] Smart element selection uses AI to choose best targets
- [ ] Context size management keeps LLM input under token limits
- [ ] Failure adaptation suggests alternative elements when selection fails

---

## üîç **Story 9: UI Inspector & Element Tree Display**
**Priority**: Should Have | **Sprint**: 3 | **Points**: 5
As a **manual tester**, I want to **view the current UI element tree and properties** so that I can **understand app structure, inspect element attributes, and debug selector issues**.

### Acceptance Criteria
1. **Given** I am on the Inspector tab
   **When** the tab content loads
   **Then** I should see:
   - "UI Elements" heading with "Refresh" button
   - List of UI elements from the current app screen
   - Each element showing: ID, element type, properties

2. **Given** I view a UI element entry
   **When** I examine the element information
   **Then** I should see:
   - Element ID in blue monospace font (e.g., `search_bar`)
   - Element type in gray text (e.g., "EditText")
   - Text content (if present)
   - Content description (if present)
   - Bounds coordinates in code format
   - Clickability status as colored badge

3. **Given** I see the sample UI elements for Swiggy app
   **When** I view the Inspector tab
   **Then** I should see these 3 elements:
   - Search bar: EditText, clickable, with content-desc "Search for restaurants"
   - Location selector: TextView, "Bengaluru, Karnataka", clickable
   - Offers banner: ImageView, "Special offers", clickable

4. **Given** I want to refresh the element tree
   **When** I click the "Refresh" button
   **Then** the system should trigger a new UI tree capture
   **And** the element list should update (visual feedback)

5. **Given** I see element properties
   **When** I examine the status badges
   **Then** clickable elements should show green "Clickable" badge
   **And** non-clickable elements should show gray "Not clickable" badge
   **And** focused elements should show blue "Focused" badge

### UI Components Required
```jsx
// Inspector Tab Content
<div className="p-4">
  <div className="space-y-3">
    <div className="flex items-center justify-between">
      <span className="text-sm font-medium">UI Elements</span>
      <button className="text-xs text-blue-600 hover:text-blue-800">Refresh</button>